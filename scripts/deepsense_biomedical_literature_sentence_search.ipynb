{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSense: a Deep Learning Method for Full-sentence Search of Biomedical Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = '/jupiter/cl17d/Project/src_new'\n",
    "base_path = './project/src_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_stats(data_file):\n",
    "    sents = set()\n",
    "    p = 0\n",
    "    n = 0\n",
    "    with open(data_file) as f:\n",
    "        next(f)\n",
    "        for row in f:\n",
    "            row = row.strip().split('\\t')\n",
    "            sents.add(f\"{row[0]}|{row[1]}\")\n",
    "            if row[-1] == '1': p += 1\n",
    "            if row[-1] == '0': n += 1\n",
    "    print(f\"{'Total Sentences':30}{len(sents)}\\n{'Positive Instances':30}{p}\")\n",
    "    print(f\"{'Negative Instances':30}{n}\\n{'Total Instances':30}{p+n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset: input/train_sentences.tsv\n",
    "\n",
    "Some sentences have more than 1 citations, so have more than 1 positive instance, resulting in 936,591 positive instances. For each positive instance, sample 2 negative instances, some negative instances may be duplicated, resulting in 1,870,387 negative instances after removal of the duplicated instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences               854101\n",
      "Positive Instances            936591\n",
      "Negative Instances            1870387\n",
      "Total Instances               2806978\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{base_path}/input/train_sentences.tsv\"\n",
    "get_train_val_stats(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Dataset: input/valid_sentences.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences               145455\n",
      "Positive Instances            148269\n",
      "Negative Instances            296128\n",
      "Total Instances               444397\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{base_path}/input/valid_sentences.tsv\"\n",
    "get_train_val_stats(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Datasets\n",
    "\n",
    "- SQL_BM25: case_SQL_testing_final_complete\n",
    "- PubMed_TFIDF: case_PubMed_testing_final_complete\n",
    "- PubMed_BM: case_PubMed_BM_testing_final_complete\n",
    "- Google_Scholar: case_Google_scholar_testing_final_complete\n",
    "\n",
    "Test datasets development process:\n",
    "\n",
    "- Develop citing sentence and cited paper pairs from PMC articles (code not available, original data not available)\n",
    "  - Output data format: citing_sentence, citing_sentence_pmid, cited_paper_pmid, (citing_sentence_original_text)\n",
    "- Acquire search returns for each citing sentence query\n",
    "  - Codes: create_test_search_PubMed.py <- PM_function.py/create_data_PubMed\n",
    "  - Output data format: citing_sentence, citing_sentence_pmid, search_returned_paper_pmid, cited_paper_pmid\n",
    "- Create final test datasets\n",
    "  - Code: create_PM_final_test.py\n",
    "\n",
    "Issues:\n",
    "\n",
    "- Exist in creating final test datasets (Code: create_PM_final_test.py)\n",
    "  - Incomplete information dictionary of total pubmed papers\n",
    "    - Forward search of citing sentence paper publishing year when its pmid not in the dictionary\n",
    "    - Skip search returned papers when their pmids not in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96950"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test sentences record\n",
    "test_sentences_records_all = json.load(open(f\"{base_path}/test_sentences_records.json\"))\n",
    "len(test_sentences_records_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with 1 publishing year        96950\n",
      "Sentences with >1 publishing year       0\n",
      "Sentences with 1+ citations             4703\n",
      "Sentences with only 1 citation          92247\n"
     ]
    }
   ],
   "source": [
    "# Check publishing year of test sentences and keep only sentences with 1 citation\n",
    "m, n, p = 0, 0, 0\n",
    "test_sentences_records = {}\n",
    "for k, v in test_sentences_records_all.items():\n",
    "    if len(v['year']) > 1: m += 1\n",
    "    if len(v['year']) == 1: n += 1\n",
    "    if len(v['citations']) > 1:\n",
    "        p += 1\n",
    "    else:\n",
    "        test_sentences_records[k] = v\n",
    "print(f\"{'Sentences with 1 publishing year':40}{n}\\n{'Sentences with >1 publishing year':40}{m}\")\n",
    "print(f\"{'Sentences with 1+ citations':40}{p}\")\n",
    "print(f\"{'Sentences with only 1 citation':40}{len(test_sentences_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations               92247\n",
      "Total unique cited papers     82639\n",
      "Sentences with >1 citations   0\n"
     ]
    }
   ],
   "source": [
    "# check citations of test sentences\n",
    "m, n = 0, 0\n",
    "cites = set()\n",
    "for v in test_sentences_records.values():\n",
    "    n += len(v['citations'])\n",
    "    if len(v['citations']) > 1: m += 1\n",
    "    for cite in v['citations']:\n",
    "        cites.add(cite)\n",
    "print(f\"{'Total citations':30}{n}\\n{'Total unique cited papers':30}{len(cites)}\\n{'Sentences with >1 citations':30}{m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with <5 tokens           217\n",
      "Sentences with >50 tokens          1273\n",
      "Sentences retained for test        90757\n"
     ]
    }
   ],
   "source": [
    "# retain only sentences with 5+ and 50- tokens for final test\n",
    "test_sentences = {}\n",
    "m, n = 0, 0\n",
    "# for k, v in test_sentences_records_all.items():\n",
    "for k, v in test_sentences_records.items():\n",
    "    if len(k.split('|')[0].split()) < 5:\n",
    "        m += 1\n",
    "    elif len(k.split('|')[0].split()) > 50:\n",
    "        n += 1\n",
    "    else:\n",
    "        test_sentences[k] = v\n",
    "print(f\"{'Sentences with <5 tokens':35}{m}\\n{'Sentences with >50 tokens':35}{n}\")\n",
    "print(f\"{'Sentences retained for test':35}{len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations               90757\n",
      "Total unique cited papers     81411\n",
      "Sentences with >1 citations   0\n"
     ]
    }
   ],
   "source": [
    "# check citations of final test sentences\n",
    "m, n = 0, 0\n",
    "cites = set()\n",
    "more_cites_sentences = {}\n",
    "for k, v in test_sentences.items():\n",
    "    n += len(v['citations'])\n",
    "    if len(v['citations']) > 1:\n",
    "        more_cites_sentences[k] = v\n",
    "        m += 1\n",
    "    for cite in v['citations']:\n",
    "        cites.add(cite)\n",
    "print(f\"{'Total citations':30}{n}\\n{'Total unique cited papers':30}{len(cites)}\\n{'Sentences with >1 citations':30}{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion for getting web pages\n",
    "def get_page(url):\n",
    "    session = requests.Session()\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) Chrome/39.0.2171.95 Safari/537.36',\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml,application/json;q=0.9,image/webp,*/*;q=0.8'}        \n",
    "    try:\n",
    "        req = session.get(url, headers=headers)\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "    req.encoding = 'utf-8'\n",
    "    if req.text == '':\n",
    "        return None\n",
    "    if req.headers['Content-Type']=='application/json':\n",
    "        return req.json()\n",
    "    return req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for query biokde\n",
    "# def biokde_search(query, year='2020'):\n",
    "#     biokde_url = 'https://biokde.com/search/'\n",
    "#     biokde_url += f'?term={query}&filter=years.1977-{year}' # sort=date,pubdate &sort_order=asc\n",
    "#     soup = BeautifulSoup(get_page(biokde_url), 'xml')\n",
    "#     counts = int(soup.find('div', attrs={'class':'reference_info'}).text.strip().split()[0].replace(',', ''))\n",
    "#     idlist = []\n",
    "#     for doc in soup.find('body').find_all('span', attrs={'class':'article_info_title'}):\n",
    "#         idlist.append(doc.a['href'].split('/')[-1])\n",
    "#     for page in range(2, int(1000/20)+1):\n",
    "#         page_url = f\"{biokde_url}&page={page}\"\n",
    "#         soup = BeautifulSoup(get_page(page_url), 'xml')\n",
    "#         for doc in soup.find('body').find_all('span', attrs={'class':'article_info_title'}):\n",
    "#             idlist.append(doc.a['href'].split('/')[-1])\n",
    "#     return counts, idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for query pubmed by entrez (tf-idf)\n",
    "# def eutils_search(query, year='2020'):\n",
    "#     eutils_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "#     eutils_url += f\"esearch.fcgi?db=pubmed&term={query}\"\n",
    "#     eutils_url += f\"&retmax=1000&sort=relevance&mindate=1977&maxdate={year}&datetype=pdat\"\n",
    "#     soup = BeautifulSoup(get_page(eutils_url), 'xml')\n",
    "#     counts = int(soup.find('Count').text)\n",
    "#     idlist = list(soup.find('IdList').stripped_strings)\n",
    "#     return counts, idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for query pubmed by web (best match)\n",
    "def pubmedweb_search(query, year='2020'):\n",
    "    pubmed_url = 'https://pubmed.ncbi.nlm.nih.gov/'\n",
    "    pubmed_url += f'?term={query}&size=200&filter=years.1977-{year}' # sort=date,pubdate &sort_order=asc\n",
    "    soup = BeautifulSoup(get_page(pubmed_url), 'xml')\n",
    "    counts = int(soup.find('meta', attrs={'name':'log_resultcount'})['content'])\n",
    "    idlist = soup.find('meta', attrs={'name':'log_displayeduids'})['content'].split(',')\n",
    "    for page in range(2, int(1000/200)+1):\n",
    "        page_url = f\"{pubmed_url}&page={page}\"\n",
    "        soup = BeautifulSoup(get_page(page_url), 'xml')\n",
    "        idlist.extend(soup.find('meta', attrs={'name':'log_displayeduids'})['content'].split(','))\n",
    "    return counts, idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for query google scholar\n",
    "# def googlescholar_search(query, year='2020'):\n",
    "#     ggs_url = 'https://scholar.google.com/scholar'\n",
    "#     ggs_url += f'?q=site:pubmed.ncbi.nlm.nih.gov {query}' # sort=date,pubdate &sort_order=asc\n",
    "#     ggs_url += f'&hl=en&as_sdt=0,10&as_ylo=1977&as_yhi={year}'\n",
    "#     soup = BeautifulSoup(get_page(ggs_url), 'html')\n",
    "#     counts = int(soup.find('div', attrs={'id':'gs_ab_md'}).text.split()[1].replace(',', ''))\n",
    "#     idlist = []\n",
    "#     for h3 in soup.find('body').find_all('h3'):\n",
    "#         idlist.append(h3.a['href'].split('/')[-2])\n",
    "#     for page in range(10, 1000, 10):\n",
    "#         page_url = f\"{ggs_url}&start={page}\"\n",
    "#         soup = BeautifulSoup(get_page(page_url), 'html')\n",
    "#         for h3 in soup.find('body').find_all('h3'):\n",
    "#             idlist.append(h3.a['href'].split('/')[-2])\n",
    "#     return counts, idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for query litsense by web (best match)\n",
    "def litsense_search(query):\n",
    "    idlist = []\n",
    "    litsense_url = 'https://www.ncbi.nlm.nih.gov/research/litsense-api/api/'\n",
    "    litsense_url += f'?query={query}&rerank=true' # sort=date,pubdate &sort_order=asc\n",
    "    for sent in get_page(litsense_url):\n",
    "        idlist.append(sent['pmid'])\n",
    "    return idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Breast cancers with HER2 amplification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "litsense_url = 'https://www.ncbi.nlm.nih.gov/research/litsense-api/api/'\n",
    "litsense_url += f'?query={query}&rerank=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page(litsense_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idlist = {}\n",
    "for i in litsense_search(query):\n",
    "    idlist[i] = idlist.get(i, 0)\n",
    "    idlist[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search in SQL_BM25**\n",
    "\n",
    "(skip, using existing test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biokde_counts, biokde_pmids = biokde_search(query, year)\n",
    "# biokde_counts, len(biokde_pmids), biokde_pmids[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search in PubMed_TD-IDF**\n",
    "\n",
    "(skip, using existing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eutils_counts, eutils_pmids = eutils_search(query, year)\n",
    "# eutils_counts, len(eutils_pmids), eutils_pmids[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search on PubMed_BM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmedweb_counts, pubmedweb_pmids = pubmedweb_search(query, year)\n",
    "# pubmedweb_counts, len(pubmedweb_pmids), pubmedweb_pmids[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "test_pubmed_bm = json.load(open('test_sents_pubmed_bm.json'))\n",
    "remaining_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45115"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pubmed_bm)#, len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in test_sentences.items():\n",
    "    if k not in sents: continue\n",
    "    if k in test_pubmed_bm: continue\n",
    "    query = ' OR '.join(k.split('|')[0].strip().split())\n",
    "    year = v['year'][0]\n",
    "#     print(query, year)\n",
    "    try:\n",
    "        counts, pmids = pubmedweb_search(query, year)\n",
    "    except:\n",
    "        remaining_set.add(k)\n",
    "        continue\n",
    "#     print(counts, len(pmids))\n",
    "    if any(i in pmids for i in v['citations']):\n",
    "        test_pubmed_bm[k] = {'year':year, 'citations':v['citations'], 'counts':counts, 'pmids':pmids}\n",
    "        n += 1\n",
    "        if n % 1000 == 0:\n",
    "            print(n)\n",
    "            json.dump(test_pubmed_bm, open('test_sents_pubmed_bm.json', 'w', encoding='utf-8'))\n",
    "        if n >= 6500: break\n",
    "json.dump(test_pubmed_bm, open('test_sents_pubmed_bm.json', 'w', encoding='utf-8'))\n",
    "len(test_pubmed_bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45115"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pubmed_bm = json.load(open('test_sents_pubmed_bm.json', 'r', encoding='utf-8'))\n",
    "len(test_pubmed_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences                                             44408\n",
      "Total Citations                                             48054\n",
      "Sentences with Top 1000 Search Returns                      18192\n",
      "Total Citations for Sentences with Top 1000 Search Returns  19718\n"
     ]
    }
   ],
   "source": [
    "# pubmed_bm dataset stat\n",
    "top1000_sentences = {} # sentences with top 1000 search returns\n",
    "num_sentences = 0\n",
    "num_citations = 0 # total number of citations\n",
    "top1000_num_citations = 0 # total number of citations in sentences with top 1000 search returns\n",
    "for k, v in test_pubmed_bm.items():\n",
    "    if k in test_sentences:\n",
    "        num_sentences += 1\n",
    "        num_citations += len(v['citations'])\n",
    "        if len(v['pmids']) > 600:\n",
    "            top1000_sentences[k] = v\n",
    "            top1000_num_citations += len(v['citations'])\n",
    "print(f\"{'Total Sentences':60}{num_sentences}\")\n",
    "print(f\"{'Total Citations':60}{num_citations}\")\n",
    "print(f\"{'Sentences with Top 1000 Search Returns':60}{len(top1000_sentences)}\")\n",
    "print(f\"{'Total Citations for Sentences with Top 1000 Search Returns':60}{top1000_num_citations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize query results into format for final test data development by create_PM_final_test.py\n",
    "# output format: citing_sentence, citing_sentence_pmid, search_returned_paper_pmid, cited_paper_pmid\n",
    "# output folder: test_pubmed_bm_search_returns\n",
    "# output file: pubmed_bm_search_returns_.csv\n",
    "out_path = '/jupiter/cl17d/Project/test_pubmed_bm_search_returns'\n",
    "num_sent = len(test_pubmed_bm)\n",
    "for i in range(0, int(num_sent/1000)+1):\n",
    "    out_file = f\"pubmed_bm_search_returns_{i}.csv\"\n",
    "    with open(f\"{out_path}/{out_file}\", \"w\", encoding=\"utf-8\") as fw:\n",
    "        for j, (k, v) in enumerate(test_pubmed_bm.items()):\n",
    "            if j < i*1000: continue\n",
    "            sent_text = k.split('|')[0]\n",
    "            sent_pmid = k.split('|')[1]\n",
    "            for cite in v['citations']:\n",
    "                for pmid in v['pmids']:\n",
    "                    if pmid != '':\n",
    "                        fw.write(f\"{sent_text}\\t{sent_pmid}\\t{pmid}\\t{cite}\\n\")\n",
    "            if j+1 == (i+1)*1000: break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# in_path = '/jupiter/cl17d/Project/test_pubmed_bm_search_returns'\n",
    "in_path = './project/test_pubmed_bm_search_returns'\n",
    "n, m = 0, 0\n",
    "for file in os.listdir(in_path):\n",
    "    with open(f\"{in_path}/{file}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for row in f:\n",
    "            row = row.strip().split(\"\\t\")\n",
    "            sentence = f\"{row[0]}|{row[1]}\"\n",
    "            pmid = row[2]\n",
    "            citation = row[3]\n",
    "            if sentence not in test_pubmed_bm:\n",
    "                n += 1\n",
    "            else:\n",
    "                if pmid not in test_pubmed_bm[sentence][\"pmids\"]:\n",
    "                    test_pubmed_bm[sentence][\"pmids\"].append(pmid)\n",
    "                if citation not in test_pubmed_bm[sentence][\"citations\"]:\n",
    "                    m += 1\n",
    "print(n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare the final pubmed bm test dataset\n",
    "# cd /jupiter/cl17d/Project/src_new\n",
    "# !python create_pubmed_search_test_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search on Google Scholar**\n",
    "\n",
    "Because Google restricts automatic crawling, Google Scholar data is not included in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggs_counts, ggs_pmids = googlescholar_search(query_or, year)\n",
    "# ggs_counts, len(ggs_pmids), ggs_pmids[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# test_google_scholar = {}\n",
    "# remaining_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in test_sentences.items():\n",
    "#     if k in test_google_scholar: continue\n",
    "#     n += 1\n",
    "#     if n % 1000 == 0:\n",
    "#         print(n)\n",
    "#         json.dump(test_google_scholar, open('test_sents_google_scholar.json', 'w', encoding='utf-8'))\n",
    "#     query = ' OR '.join(k.split('|')[0].strip().split())\n",
    "#     year = v['year'][0]\n",
    "# #     print(query, year)\n",
    "#     try:\n",
    "#         counts, pmids = googlescholar_search(query, year)\n",
    "#     except:\n",
    "#         remaining_set.add(k)\n",
    "#         continue\n",
    "# #     print(counts, len(pmids))\n",
    "#     test_google_scholar[k] = {'year':year, 'citations':v['citations'], 'counts':counts, 'pmids':pmids}\n",
    "# json.dump(test_google_scholar, open('test_sents_google_scholar.json', 'w', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the existing SQL_BM25 test dataset, the ranks of search returns for each sentence-citation pair are the same. Also the search returns include the top 1000 search results. We will only use the top 500 search results in the study.\n",
    "\n",
    "Because of the SQL BM25 dataset can not be processed for getting the top 500 search returns, we use the top 1000 search returns in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for processing the test datasets to retain the top 500 search returns\n",
    "# def top500_search_returns(input_path, output_path):\n",
    "#     citation_ranks = {}\n",
    "#     for file in os.listdir(input_path):\n",
    "#         search_results = {}\n",
    "#         with open(f\"{output_path}/{file}\", \"w\", encoding=\"utf-8\") as fw:\n",
    "#             with open(f\"{input_path}/{file}\", \"r\", encoding=\"utf-8\") as fr:\n",
    "#                 fw.write(fr.readline())\n",
    "#                 for line in  fr:\n",
    "#                     line = line.strip().split('\\t')\n",
    "#                     sentence = f\"{line[0]}|{line[1]}|{line[3]}\"\n",
    "#                     search_return = line[2]\n",
    "#                     citation = line[3]\n",
    "#                     citation_rank = int(line[-1])\n",
    "#                     search_results[sentence] = search_results.get(sentence, 0)\n",
    "#                     search_results[sentence] += 1\n",
    "#                     if search_return == citation:\n",
    "#                         citation_ranks[sentence] = {'position':search_results[sentence], 'citation':'\\t'.join(line)}\n",
    "#                     if citation_rank <= 500 and search_results[sentence] <= 500:\n",
    "#                         fw.write('\\t'.join(line)+'\\n')\n",
    "# #     return citation_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process the SQL_BM25 test dataset\n",
    "# input_path = f\"{base_path}/case_SQL_testing_final_complete\"\n",
    "# output_path = f\"{base_path}/test_dataset_sql_bm25\"\n",
    "# top500_search_returns(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process the PubMed_TFIDF test dataset\n",
    "# input_path = f\"{base_path}/case_PubMed_testing_final_complete\"\n",
    "# output_path = f\"{base_path}/test_dataset_pubmed_tfidf\"\n",
    "# top500_search_returns(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process the PubMed_TFIDF test dataset\n",
    "# input_path = f\"{base_path}/test_pubmed_bm_dataset\"\n",
    "# output_path = f\"{base_path}/test_dataset_pubmed_bm\"\n",
    "# top500_search_returns(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=2 python train_sentences_new.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test dataset of SQL_BM25\n",
    "# !CUDA_VISIBLE_DEVICES=2 python test_sentences_sql_bm25.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test dataset of PubMed_TFIDF\n",
    "# !CUDA_VISIBLE_DEVICES=2 python test_sentences_pubmed_tfidf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test dataset of PubMed_BM\n",
    "# !CUDA_VISIBLE_DEVICES=2 python test_sentences_pubmed_bm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for stats calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_stats(test_path, test_sentences_records):\n",
    "    sents = set()\n",
    "    extra_sents = set()\n",
    "    cites = set()\n",
    "    extra_cites = set()\n",
    "    n, m = 0, 0\n",
    "    for file in os.listdir(f\"{test_path}\"):\n",
    "        with open(f\"{test_path}/{file}\") as ifile:\n",
    "            next(ifile)\n",
    "            for row in ifile:\n",
    "                row = row.strip().split(\"\\t\")\n",
    "                sentence = f\"{row[0]}|{row[1]}\"\n",
    "                citation = row[3]\n",
    "                if sentence in test_sentences_records:\n",
    "                    sents.add(sentence)\n",
    "                    cites.add(citation)\n",
    "                    n += 1\n",
    "                else:\n",
    "                    extra_sents.add(sentence)\n",
    "                    extra_cites.add(citation)\n",
    "                    m += 1 \n",
    "                    \n",
    "    #             if citation in test_sentences_records[sentence]['citations']: m += 1\n",
    "    print(f\"Test Sentences: {len(sents):12}\\tExtra Sentences: {len(extra_sents)}\")\n",
    "    print(f\"Test Citations: {len(cites):12}\\tExtra Citations: {len(extra_cites.difference(cites))}\")\n",
    "    print(f\"Test Instances: {n:12}\\tExtra Instances: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_stats(pred_path, test_sentences_records):\n",
    "    sents = set()\n",
    "    extra_sents = set()\n",
    "    cites = set()\n",
    "    extra_cites = set()\n",
    "    n, m = 0, 0\n",
    "    for file in os.listdir(f\"{pred_path}\"):\n",
    "        with open(f\"{pred_path}/{file}\") as ifile:\n",
    "            next(ifile)\n",
    "            for row in ifile:\n",
    "                row = row.strip().split(\"\\t\")\n",
    "                sentence = '|'.join(row[0].split('|')[:2])\n",
    "                citation = row[1]\n",
    "                if sentence in test_sentences_records:\n",
    "                    sents.add(sentence)\n",
    "                    cites.add(citation)\n",
    "                    n += 1\n",
    "                else:\n",
    "                    extra_sents.add(sentence)\n",
    "                    extra_cites.add(citation)\n",
    "                    m += 1\n",
    "    #             if citation in test_sentences_records[sentence]['citations']: m += 1\n",
    "    print(f\"Test Sentences: {len(sents):12}\\tExtra Sentences: {len(extra_sents)}\")\n",
    "    print(f\"Test Citations: {len(cites):12}\\tExtra Citations: {len(extra_cites.difference(cites))}\")\n",
    "    print(f\"Test Instances: {n:12}\\tExtra Instances: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_results(pred_path, test_sentences_records):\n",
    "    pred_results = {}\n",
    "    serank_top1, serank_top10, serank_top20, serank_top100 = 0, 0, 0, 0\n",
    "    rerank_top1, rerank_top10, rerank_top20, rerank_top100 = 0, 0, 0, 0\n",
    "    better_serank, tie_rank, better_rerank = 0, 0, 0\n",
    "    num_dup_citations = 0\n",
    "    for file in os.listdir(pred_path):\n",
    "        with open(f\"{pred_path}/{file}\") as ifile:\n",
    "            next(ifile)\n",
    "            for row in ifile:\n",
    "                row = row.strip().split(\"\\t\")\n",
    "                sentence = '|'.join(row[0].split('|')[:2])\n",
    "                citation = row[1]\n",
    "                serank = int(row[2])\n",
    "                rerank = int(row[3])\n",
    "                if sentence in test_sentences_records:\n",
    "                    if citation in test_sentences_records[sentence]['citations']:\n",
    "                        pred_results[sentence] = pred_results.get(sentence, {})\n",
    "                        if citation not in pred_results[sentence]:\n",
    "                            pred_results[sentence][citation] = pred_results[sentence].get(citation, [])\n",
    "                            pred_results[sentence][citation].append((serank, rerank))\n",
    "                            if serank == 1: serank_top1 += 1\n",
    "                            if serank <= 10: serank_top10 += 1\n",
    "                            if serank <= 20: serank_top20 += 1\n",
    "                            if serank <= 100: serank_top100 += 1\n",
    "\n",
    "                            if rerank == 1: rerank_top1 += 1\n",
    "                            if rerank <= 10: rerank_top10 += 1\n",
    "                            if rerank <= 20: rerank_top20 += 1\n",
    "                            if rerank <= 100: rerank_top100 += 1\n",
    "\n",
    "                            if serank < rerank: better_serank += 1\n",
    "                            if serank == rerank: tie_rank += 1\n",
    "                            if rerank < serank: better_rerank += 1\n",
    "                        else: num_dup_citations += 1\n",
    "    \n",
    "    print(f\"{'Rank':20}\\t{'Top1':8}\\t{'Top10':8}\\t{'Top20':8}\\t{'Top100'}\")\n",
    "    print(f\"{80*'-'}\")\n",
    "    print(f\"{'Search':20}\\t{serank_top1:<8}\\t{serank_top10:<8}\\t{serank_top20:<8}\\t{serank_top100}\")\n",
    "    print(f\"{'Rerank':20}\\t{rerank_top1:<8}\\t{rerank_top10:<8}\\t{rerank_top20:<8}\\t{rerank_top100}\")\n",
    "    print(f\"{'Duplicated citations':20}\\t{num_dup_citations}\")\n",
    "    print(f\"{'Search Win':20}\\t{better_serank}\")\n",
    "    print(f\"{'Tie':20}\\t{tie_rank}\")\n",
    "    print(f\"{'Rerank Improvement':20}\\t{better_rerank}\")\n",
    "    \n",
    "    return pred_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results: SQL_BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        95230\tExtra Sentences: 1984\n",
      "Test Citations:        89041\tExtra Citations: 1884\n",
      "Test Instances:    100287085\tExtra Instances: 2265000\n"
     ]
    }
   ],
   "source": [
    "test_path = f\"{base_path}/test_dataset_sql_bm25\"\n",
    "get_test_stats(test_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        95230\tExtra Sentences: 1984\n",
      "Test Citations:        89041\tExtra Citations: 1884\n",
      "Test Instances:       100111\tExtra Instances: 2282\n",
      "\n",
      "\n",
      "\n",
      "Rank                \tTop1    \tTop10   \tTop20   \tTop100\n",
      "--------------------------------------------------------------------------------\n",
      "Search              \t18737   \t41234   \t48979   \t68804\n",
      "Rerank              \t24747   \t56260   \t66507   \t87751\n",
      "Duplicated citations\t9\n",
      "Search Win          \t28002\n",
      "Tie                 \t13067\n",
      "Rerank Improvement  \t59033\n"
     ]
    }
   ],
   "source": [
    "# test results of sentences with SQL_BM25 top 500 search returns (New)\n",
    "pred_path = f\"{base_path}/src_model_full_sentence/test_results_sql_bm25\"\n",
    "get_pred_stats(pred_path, test_sentences)\n",
    "print('\\n\\n')\n",
    "results_sql = get_pred_results(pred_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recently new genome editing methods zinc finger nucleases zfns transcription activator like nucleases talens clustered regularly interspaced short palindromic repeats cas9 endonuclease crispr cas9 shown powerful tools directly mutating genome targeted gene deletions|28224990 {'21700836': [(70, 30), (70, 30)]}\n",
      "large scale mining assay data revealed different facets promiscuity|25339989 {'24358872': [(1, 1), (1, 70)]}\n",
      "pae found patients switched aripiprazole sudden discontinuation previous antipsychotic medication showed increase symptom severity first week switching|25792838 {'19442491': [(1, 1), (1, 1)]}\n",
      "psychiatric problems euphoria hypomania suicidal ideation apathy new cases impulse control disorders icds documented stn dbs hälbig lim volkmann moum castrioto hack|26892884 {'19236471': [(12, 3), (12, 3)], '19553125': [(3, 37)]}\n",
      "finally several studies demonstrated decreased frequency impaired function tregs ssc|28890870 {'20105169': [(19, 35), (19, 35)], '21419712': [(6, 7)]}\n",
      "whether adolescent permitted parents smoke predicts smoking initiation maintenance even predicts preferences future smoke free living quarters|22152017 {'20852326': [(188, 61), (188, 61)]}\n",
      "clinical features hd patients asia resembled western population note terms atypical onset juvenile hd jhd sporadic hd asian patients bear characteristics deliberated following parts|26112725 {'22453898': [(28, 1), (28, 60)]}\n",
      "previous cellular isolation methods use cd146 marker mainly performed bm mscs human umbilical cord mscs|29313241 {'25232467': [(131, 1), (131, 554)]}\n",
      "however due several issues including hairpin tendency ligate different strands chimeric reads lower read quality sequencing speed complement strand reportedly caused secondary structure changes strand rezipping sequencing approach deprecated favor 1d 2 sequencing may 2017|29375809 {'28928943': [(1, 1), (1, 124)]}\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Number of citations search returns broken into 2 files\n",
    "n = 0\n",
    "sentences_in_2_files = {}\n",
    "for k, v in results_sql.items():\n",
    "    for ck, cv in v.items():\n",
    "        if len(cv) > 1:\n",
    "            sentences_in_2_files[k] = v\n",
    "            print(k, v)\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95230"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95230, 28002, 100102, 1, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serank = []\n",
    "better_serank = 0\n",
    "for k, v in results_sql.items():\n",
    "    for ck, cv in v.items():\n",
    "        serank.append(cv[0][0])\n",
    "        if cv[0][0] < cv[0][1]: better_serank += 1\n",
    "len(results_sql), better_serank, len(serank), min(serank), max(serank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results: PubMed_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        95230\tExtra Sentences: 1720\n",
      "Test Citations:        89013\tExtra Citations: 1656\n",
      "Test Instances:     98177227\tExtra Instances: 1950842\n"
     ]
    }
   ],
   "source": [
    "test_path = f\"{base_path}/test_dataset_pubmed_tfidf\"\n",
    "get_test_stats(test_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        60600\tExtra Sentences: 1012\n",
      "Test Citations:        56778\tExtra Citations: 958\n",
      "Test Instances:        62821\tExtra Instances: 1133\n",
      "\n",
      "\n",
      "\n",
      "Rank                \tTop1    \tTop10   \tTop20   \tTop100\n",
      "--------------------------------------------------------------------------------\n",
      "Search              \t9325    \t22489   \t27253   \t40411\n",
      "Rerank              \t17546   \t37816   \t43681   \t55232\n",
      "Duplicated citations\t3\n",
      "Search Win          \t15550\n",
      "Tie                 \t6419\n",
      "Rerank Improvement  \t40849\n"
     ]
    }
   ],
   "source": [
    "# test results of sentences with PubMed TFIDF top 500 search returns\n",
    "pred_path = f\"{base_path}/src_model_full_sentence/test_results_pubmed_tfidf\"\n",
    "get_pred_stats(pred_path, test_sentences)\n",
    "print('\\n\\n')\n",
    "results_tfidf = get_pred_results(pred_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of citations search returns broken into 2 files\n",
    "n = 0\n",
    "for k, v in results_tfidf.items():\n",
    "    for ck, cv in v.items():\n",
    "        if len(cv) > 1:\n",
    "            print(k, v)\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60600, 15550, 62818, 1, 998)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serank = []\n",
    "better_serank = 0\n",
    "for k, v in results_tfidf.items():\n",
    "    for ck, cv in v.items():\n",
    "        serank.append(cv[0][0])\n",
    "        if cv[0][0] < cv[0][1]: better_serank += 1\n",
    "len(results_tfidf), better_serank, len(serank), min(serank), max(serank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \tTop1    \tTop10   \tTop20   \tTop100  \n",
      "------------------------------------------------------------------------------------------\n",
      "Sentences in SQL/TFIDF        \t60600   \t60600   \t62818   \n",
      "SQL Search Results            \t16486   \t33586   \t38663   \t49872   \n",
      "SQL Rerank Results            \t20073   \t40878   \t46591   \t57297   \n",
      "TFIDF Search Results          \t9325    \t22489   \t27253   \t40411   \n",
      "TFIDF Rerank Results          \t17546   \t37816   \t43681   \t55232   \n"
     ]
    }
   ],
   "source": [
    "n_sql, m = 0, 0\n",
    "sents = set()\n",
    "n_sql_se_1, n_sql_se_10, n_sql_se_20, n_sql_se_100 = 0, 0, 0, 0\n",
    "n_sql_re_1, n_sql_re_10, n_sql_re_20, n_sql_re_100 = 0, 0, 0, 0\n",
    "n_tfidf_se_1, n_tfidf_se_10, n_tfidf_se_20, n_tfidf_se_100 = 0, 0, 0, 0\n",
    "n_tfidf_re_1, n_tfidf_re_10, n_tfidf_re_20, n_tfidf_re_100 = 0, 0, 0, 0\n",
    "for k,v in results_tfidf.items():\n",
    "    if k in results_sql:\n",
    "        m += 1\n",
    "        for i in v:\n",
    "            if i in results_sql[k]:\n",
    "                n_sql += 1\n",
    "                sents.add(k)\n",
    "                if results_sql[k][i][0][0] == 1: n_sql_se_1 += 1\n",
    "                if results_sql[k][i][0][0] <= 10: n_sql_se_10 += 1\n",
    "                if results_sql[k][i][0][0] <= 20: n_sql_se_20 += 1\n",
    "                if results_sql[k][i][0][0] <= 100: n_sql_se_100 += 1\n",
    "                \n",
    "                if results_sql[k][i][0][1] == 1: n_sql_re_1 += 1\n",
    "                if results_sql[k][i][0][1] <= 10: n_sql_re_10 += 1\n",
    "                if results_sql[k][i][0][1] <= 20: n_sql_re_20 += 1\n",
    "                if results_sql[k][i][0][1] <= 100: n_sql_re_100 += 1\n",
    "                \n",
    "                if results_tfidf[k][i][0][0] == 1: n_tfidf_se_1 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 10: n_tfidf_se_10 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 20: n_tfidf_se_20 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 100: n_tfidf_se_100 += 1\n",
    "                \n",
    "                if results_tfidf[k][i][0][1] == 1: n_tfidf_re_1 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 10: n_tfidf_re_10 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 20: n_tfidf_re_20 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 100: n_tfidf_re_100 += 1\n",
    "\n",
    "print(f\"{' ':30}\\t{'Top1':8}\\t{'Top10':8}\\t{'Top20':8}\\t{'Top100':8}\")\n",
    "print(f\"{90*'-'}\")\n",
    "print(f\"{'Sentences in SQL/TFIDF':30}\\t{m:<8}\\t{len(sents):<8}\\t{n_sql:<8}\")\n",
    "print(f\"{'SQL Search Results':30}\\t{n_sql_se_1:<8}\\t{n_sql_se_10:<8}\\t{n_sql_se_20:<8}\\t{n_sql_se_100:<8}\")\n",
    "print(f\"{'SQL Rerank Results':30}\\t{n_sql_re_1:<8}\\t{n_sql_re_10:<8}\\t{n_sql_re_20:<8}\\t{n_sql_re_100:<8}\")\n",
    "print(f\"{'TFIDF Search Results':30}\\t{n_tfidf_se_1:<8}\\t{n_tfidf_se_10:<8}\\t{n_tfidf_se_20:<8}\\t{n_tfidf_se_100:<8}\")\n",
    "print(f\"{'TFIDF Rerank Results':30}\\t{n_tfidf_re_1:<8}\\t{n_tfidf_re_10:<8}\\t{n_tfidf_re_20:<8}\\t{n_tfidf_re_100:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sql[k][i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results: PubMed_BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        41120\tExtra Sentences: 3995\n",
      "Test Citations:        38835\tExtra Citations: 6999\n",
      "Test Instances:     27026803\tExtra Instances: 5207044\n"
     ]
    }
   ],
   "source": [
    "# test_path = f\"{base_path}/case_PubMed_BM_testing_final_complete\"\n",
    "test_path = f\"{base_path}/test_dataset_pubmed_bm\"\n",
    "get_test_stats(test_path, test_sentences) # top1000_sentences, test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        16824\tExtra Sentences: 28291\n",
      "Test Citations:        16390\tExtra Citations: 29444\n",
      "Test Instances:     14501168\tExtra Instances: 17732679\n"
     ]
    }
   ],
   "source": [
    "# test_path = f\"{base_path}/case_PubMed_BM_testing_final_complete\"\n",
    "test_path = f\"{base_path}/test_dataset_pubmed_bm\"\n",
    "get_test_stats(test_path, top1000_sentences) # top1000_sentences, test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        11739\tExtra Sentences: 10511\n",
      "Test Citations:        11965\tExtra Citations: 10294\n",
      "Test Instances:        12256\tExtra Instances: 11020\n",
      "\n",
      "\n",
      "\n",
      "Rank                \tTop1    \tTop20   \tTop100\n",
      "-----------------------------------------------------------------\n",
      "Search              \t456     \t4329    \t7130\n",
      "Rerank              \t4644    \t9472    \t11337\n",
      "Duplicated citations\t0\n",
      "Search Win          \t1625\n",
      "Tie                 \t427\n",
      "Rerank Improvement  \t10204\n"
     ]
    }
   ],
   "source": [
    "# test results of sentences with PubMed BM top 500 search returns\n",
    "pred_path = f\"{base_path}/src_model_full_sentence/test_results_pubmed_bm\"\n",
    "get_pred_stats(pred_path, top1000_sentences) # top1000_sentences, test_sentences\n",
    "print('\\n\\n')\n",
    "results_bm = get_pred_results(pred_path, top1000_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for k, v in results_bm.items():\n",
    "    for ck, cv in v.items():\n",
    "        if len(cv) > 1:\n",
    "            print(k, v)\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10782, 1400, 10782, 1, 979)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serank = []\n",
    "better_serank = 0\n",
    "for k, v in results_bm.items():\n",
    "    for ck, cv in v.items():\n",
    "        serank.append(cv[0][0])\n",
    "        if cv[0][0] > 1000: print(k, v)\n",
    "        if cv[0][0] < cv[0][1]: better_serank += 1\n",
    "len(results_bm), better_serank, len(serank), min(serank), max(serank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \tTop1    \tTop20   \tTop100  \n",
      "---------------------------------------------------------------------------\n",
      "Test Citations in SQL/TFIDF   \t11739   \t10790   \t11145   \n",
      "SQL Search Results            \t3613    \t7642    \t9394    \n",
      "SQL Rerank Results            \t4204    \t8871    \t10433   \n",
      "TFIDF Search Results          \t2249    \t5956    \t8156    \n",
      "TFIDF Rerank Results          \t3700    \t8356    \t10154   \n",
      "BM Search Results             \t448     \t4249    \t6841    \n",
      "BM Rerank Results             \t4433    \t8777    \t10374   \n"
     ]
    }
   ],
   "source": [
    "n_sql, n_tfidf = 0, 0\n",
    "n_sql_se_1, n_sql_se_20, n_sql_se_100 = 0, 0, 0\n",
    "n_sql_re_1, n_sql_re_20, n_sql_re_100 = 0, 0, 0\n",
    "n_tfidf_se_1, n_tfidf_se_20, n_tfidf_se_100 = 0, 0, 0\n",
    "n_tfidf_re_1, n_tfidf_re_20, n_tfidf_re_100 = 0, 0, 0\n",
    "n_bm_se_1, n_bm_se_20, n_bm_se_100 = 0, 0, 0\n",
    "n_bm_re_1, n_bm_re_20, n_bm_re_100 = 0, 0, 0\n",
    "for k,v in results_bm.items():\n",
    "    if k in results_sql and k in results_tfidf:\n",
    "        n_sql += 1\n",
    "        for i in v:\n",
    "            if i in results_sql[k] and i in results_tfidf[k]:\n",
    "                n_tfidf += 1\n",
    "                if results_sql[k][i][0][0] == 1: n_sql_se_1 += 1\n",
    "                if results_sql[k][i][0][0] <= 20: n_sql_se_20 += 1\n",
    "                if results_sql[k][i][0][0] <= 100: n_sql_se_100 += 1\n",
    "                \n",
    "                if results_sql[k][i][0][1] == 1: n_sql_re_1 += 1\n",
    "                if results_sql[k][i][0][1] <= 20: n_sql_re_20 += 1\n",
    "                if results_sql[k][i][0][1] <= 100: n_sql_re_100 += 1\n",
    "                \n",
    "                if results_tfidf[k][i][0][0] == 1: n_tfidf_se_1 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 20: n_tfidf_se_20 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 100: n_tfidf_se_100 += 1\n",
    "                \n",
    "                if results_tfidf[k][i][0][1] == 1: n_tfidf_re_1 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 20: n_tfidf_re_20 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 100: n_tfidf_re_100 += 1\n",
    "                \n",
    "                if results_bm[k][i][0][0] == 1: n_bm_se_1 += 1\n",
    "                if results_bm[k][i][0][0] <= 20: n_bm_se_20 += 1\n",
    "                if results_bm[k][i][0][0] <= 100: n_bm_se_100 += 1\n",
    "                \n",
    "                if results_bm[k][i][0][1] == 1: n_bm_re_1 += 1\n",
    "                if results_bm[k][i][0][1] <= 20: n_bm_re_20 += 1\n",
    "                if results_bm[k][i][0][1] <= 100: n_bm_re_100 += 1\n",
    "print(f\"{' ':30}\\t{'Top1':8}\\t{'Top20':8}\\t{'Top100':8}\")\n",
    "print(f\"{75*'-'}\")\n",
    "print(f\"{'Test Citations in SQL/TFIDF':30}\\t{len(results_bm):<8}\\t{n_sql:<8}\\t{n_tfidf:<8}\")\n",
    "print(f\"{'SQL Search Results':30}\\t{n_sql_se_1:<8}\\t{n_sql_se_20:<8}\\t{n_sql_se_100:<8}\")\n",
    "print(f\"{'SQL Rerank Results':30}\\t{n_sql_re_1:<8}\\t{n_sql_re_20:<8}\\t{n_sql_re_100:<8}\")\n",
    "print(f\"{'TFIDF Search Results':30}\\t{n_tfidf_se_1:<8}\\t{n_tfidf_se_20:<8}\\t{n_tfidf_se_100:<8}\")\n",
    "print(f\"{'TFIDF Rerank Results':30}\\t{n_tfidf_re_1:<8}\\t{n_tfidf_re_20:<8}\\t{n_tfidf_re_100:<8}\")\n",
    "print(f\"{'BM Search Results':30}\\t{n_bm_se_1:<8}\\t{n_bm_se_20:<8}\\t{n_bm_se_100:<8}\")\n",
    "print(f\"{'BM Rerank Results':30}\\t{n_bm_re_1:<8}\\t{n_bm_re_20:<8}\\t{n_bm_re_100:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    \t# of Citations  \tMin # of Words  \tMax # of Words  \tAvg # of Words  \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "SQL Search Top1     \t3613            \t5               \t50              \t20.099916966509827\n",
      "SQL Rerank Top1     \t4204            \t5               \t50              \t20.00023786869648\n",
      "\n",
      "SQL Search Top20    \t7642            \t5               \t50              \t20.076681496990318\n",
      "SQL Rerank Top20    \t8871            \t5               \t50              \t20.08071243377297\n",
      "\n",
      "SQL Search Top100   \t9394            \t5               \t50              \t20.06642537790079\n",
      "SQL Rerank Top100   \t10433           \t5               \t50              \t20.082526598293875\n",
      "\n",
      "TFIDF Search Top1   \t2249            \t5               \t50              \t19.895064473099154\n",
      "TFIDF Rerank Top1   \t3700            \t5               \t50              \t20.253783783783785\n",
      "\n",
      "TFIDF Search Top20  \t5956            \t5               \t50              \t20.087642713230355\n",
      "TFIDF Rerank Top20  \t8356            \t5               \t50              \t20.160842508377215\n",
      "\n",
      "TFIDF Search Top100 \t8156            \t5               \t50              \t20.059220205983326\n",
      "TFIDF Rerank Top100 \t10154           \t5               \t50              \t20.13728579870002\n",
      "\n",
      "PBM Search Top1     \t448             \t5               \t50              \t18.334821428571427\n",
      "PBM Rerank Top1     \t4433            \t5               \t50              \t19.897135122941574\n",
      "\n",
      "PBM Search Top20    \t4249            \t5               \t50              \t19.662273476112027\n",
      "PBM Rerank Top20    \t8777            \t5               \t50              \t19.979150051270366\n",
      "\n",
      "PBM Search Top100   \t6841            \t5               \t50              \t19.875895336939045\n",
      "PBM Rerank Top100   \t10374           \t5               \t50              \t20.011760169654906\n"
     ]
    }
   ],
   "source": [
    "n_sql_se_1, n_sql_se_20, n_sql_se_100 = [], [], []\n",
    "n_sql_re_1, n_sql_re_20, n_sql_re_100 = [], [], []\n",
    "n_tfidf_se_1, n_tfidf_se_20, n_tfidf_se_100 = [], [], []\n",
    "n_tfidf_re_1, n_tfidf_re_20, n_tfidf_re_100 = [], [], []\n",
    "n_pbm_se_1, n_pbm_se_20, n_pbm_se_100 = [], [], []\n",
    "n_pbm_re_1, n_pbm_re_20, n_pbm_re_100 = [], [], []\n",
    "for k,v in results_bm.items():\n",
    "    if k in results_sql and k in results_tfidf:\n",
    "        n_sql += 1\n",
    "        for i in v:\n",
    "            if i in results_sql[k] and i in results_tfidf[k]:\n",
    "                n_tfidf += 1\n",
    "                if results_bm[k][i][0][0] == 1: n_pbm_se_1.append(len(k.split()))\n",
    "                if results_bm[k][i][0][0] <= 20: n_pbm_se_20.append(len(k.split()))\n",
    "                if results_bm[k][i][0][0] <= 100: n_pbm_se_100.append(len(k.split()))\n",
    "\n",
    "                if results_bm[k][i][0][1] == 1: n_pbm_re_1.append(len(k.split()))\n",
    "                if results_bm[k][i][0][1] <= 20: n_pbm_re_20.append(len(k.split()))\n",
    "                if results_bm[k][i][0][1] <= 100: n_pbm_re_100.append(len(k.split()))\n",
    "                \n",
    "                if results_sql[k][i][0][0] == 1: n_sql_se_1.append(len(k.split()))\n",
    "                if results_sql[k][i][0][0] <= 20: n_sql_se_20.append(len(k.split()))\n",
    "                if results_sql[k][i][0][0] <= 100: n_sql_se_100.append(len(k.split()))\n",
    "                \n",
    "                if results_sql[k][i][0][1] == 1: n_sql_re_1.append(len(k.split()))\n",
    "                if results_sql[k][i][0][1] <= 20: n_sql_re_20.append(len(k.split()))\n",
    "                if results_sql[k][i][0][1] <= 100: n_sql_re_100.append(len(k.split()))\n",
    "                \n",
    "                if results_tfidf[k][i][0][0] == 1: n_tfidf_se_1.append(len(k.split()))\n",
    "                if results_tfidf[k][i][0][0] <= 20: n_tfidf_se_20.append(len(k.split()))\n",
    "                if results_tfidf[k][i][0][0] <= 100: n_tfidf_se_100.append(len(k.split()))\n",
    "                \n",
    "                if results_tfidf[k][i][0][1] == 1: n_tfidf_re_1.append(len(k.split()))\n",
    "                if results_tfidf[k][i][0][1] <= 20: n_tfidf_re_20.append(len(k.split()))\n",
    "                if results_tfidf[k][i][0][1] <= 100: n_tfidf_re_100.append(len(k.split()))\n",
    "print(f\"{' ':20}\\t{'# of Citations':16}\\t{'Min # of Words':16}\\t{'Max # of Words':16}\\t{'Avg # of Words':16}\")\n",
    "print(f\"{115*'-'}\")\n",
    "print(f\"{'SQL Search Top1':20}\\t{len(n_sql_se_1):<16}\\t{min(n_sql_se_1):<16}\\t{max(n_sql_se_1):<16}\\t{sum(n_sql_se_1)/len(n_sql_se_1):<16}\")\n",
    "print(f\"{'SQL Rerank Top1':20}\\t{len(n_sql_re_1):<16}\\t{min(n_sql_re_1):<16}\\t{max(n_sql_re_1):<16}\\t{sum(n_sql_re_1)/len(n_sql_re_1):<16}\")\n",
    "print()\n",
    "print(f\"{'SQL Search Top20':20}\\t{len(n_sql_se_20):<16}\\t{min(n_sql_se_20):<16}\\t{max(n_sql_se_20):<16}\\t{sum(n_sql_se_20)/len(n_sql_se_20):<16}\")\n",
    "print(f\"{'SQL Rerank Top20':20}\\t{len(n_sql_re_20):<16}\\t{min(n_sql_re_20):<16}\\t{max(n_sql_re_20):<16}\\t{sum(n_sql_re_20)/len(n_sql_re_20):<16}\")\n",
    "print()\n",
    "print(f\"{'SQL Search Top100':20}\\t{len(n_sql_se_100):<16}\\t{min(n_sql_se_100):<16}\\t{max(n_sql_se_100):<16}\\t{sum(n_sql_se_100)/len(n_sql_se_100):<16}\")\n",
    "print(f\"{'SQL Rerank Top100':20}\\t{len(n_sql_re_100):<16}\\t{min(n_sql_re_100):<16}\\t{max(n_sql_re_100):<16}\\t{sum(n_sql_re_100)/len(n_sql_re_100):<16}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Search Top1':20}\\t{len(n_tfidf_se_1):<16}\\t{min(n_tfidf_se_1):<16}\\t{max(n_tfidf_se_1):<16}\\t{sum(n_tfidf_se_1)/len(n_tfidf_se_1):<16}\")\n",
    "print(f\"{'TFIDF Rerank Top1':20}\\t{len(n_tfidf_re_1):<16}\\t{min(n_tfidf_re_1):<16}\\t{max(n_tfidf_re_1):<16}\\t{sum(n_tfidf_re_1)/len(n_tfidf_re_1):<16}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Search Top20':20}\\t{len(n_tfidf_se_20):<16}\\t{min(n_tfidf_se_20):<16}\\t{max(n_tfidf_se_20):<16}\\t{sum(n_tfidf_se_20)/len(n_tfidf_se_20):<16}\")\n",
    "print(f\"{'TFIDF Rerank Top20':20}\\t{len(n_tfidf_re_20):<16}\\t{min(n_tfidf_re_20):<16}\\t{max(n_tfidf_re_20):<16}\\t{sum(n_tfidf_re_20)/len(n_tfidf_re_20):<16}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Search Top100':20}\\t{len(n_tfidf_se_100):<16}\\t{min(n_tfidf_se_100):<16}\\t{max(n_tfidf_se_100):<16}\\t{sum(n_tfidf_se_100)/len(n_tfidf_se_100):<16}\")\n",
    "print(f\"{'TFIDF Rerank Top100':20}\\t{len(n_tfidf_re_100):<16}\\t{min(n_tfidf_re_100):<16}\\t{max(n_tfidf_re_100):<16}\\t{sum(n_tfidf_re_100)/len(n_tfidf_re_100):<16}\")\n",
    "print()\n",
    "print(f\"{'PBM Search Top1':20}\\t{len(n_pbm_se_1):<16}\\t{min(n_pbm_se_1):<16}\\t{max(n_pbm_se_1):<16}\\t{sum(n_pbm_se_1)/len(n_pbm_se_1):<16}\")\n",
    "print(f\"{'PBM Rerank Top1':20}\\t{len(n_pbm_re_1):<16}\\t{min(n_pbm_re_1):<16}\\t{max(n_pbm_re_1):<16}\\t{sum(n_pbm_re_1)/len(n_pbm_re_1):<16}\")\n",
    "print()\n",
    "print(f\"{'PBM Search Top20':20}\\t{len(n_pbm_se_20):<16}\\t{min(n_pbm_se_20):<16}\\t{max(n_pbm_se_20):<16}\\t{sum(n_pbm_se_20)/len(n_pbm_se_20):<16}\")\n",
    "print(f\"{'PBM Rerank Top20':20}\\t{len(n_pbm_re_20):<16}\\t{min(n_pbm_re_20):<16}\\t{max(n_pbm_re_20):<16}\\t{sum(n_pbm_re_20)/len(n_pbm_re_20):<16}\")\n",
    "print()\n",
    "print(f\"{'PBM Search Top100':20}\\t{len(n_pbm_se_100):<16}\\t{min(n_pbm_se_100):<16}\\t{max(n_pbm_se_100):<16}\\t{sum(n_pbm_se_100)/len(n_pbm_se_100):<16}\")\n",
    "print(f\"{'PBM Rerank Top100':20}\\t{len(n_pbm_re_100):<16}\\t{min(n_pbm_re_100):<16}\\t{max(n_pbm_re_100):<16}\\t{sum(n_pbm_re_100)/len(n_pbm_re_100):<16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('include cellprofiler imagej bioimagexd icy omero ebimage|24564609',\n",
       " {'17936939': [(42, 58)], '20338898': [(2, 12)]},\n",
       " {'17936939': [(88, 37)], '20338898': [(1, 11)]},\n",
       " {'17936939': [(7, 7)], '20338898': [(155, 14)]})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = list(results_bm.keys())[6]\n",
    "sent, results_sql[sent], results_tfidf[sent], results_bm[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"{base_path}/test_dataset_sql_bm25\"\n",
    "with open(\"sent10_sql_bm25.csv\", \"w\", encoding=\"utf-8\") as fwriter:\n",
    "    for file in os.listdir(f\"{test_path}\"):\n",
    "        with open(f\"{test_path}/{file}\") as freader:\n",
    "            next(freader)\n",
    "            for line in freader:\n",
    "                row = line.strip().split(\"\\t\")\n",
    "                sentence = f\"{row[0]}|{row[1]}\"\n",
    "                citation = row[3]\n",
    "                if sentence == sent and citation in ['18977449']:\n",
    "                    fwriter.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"{base_path}/test_dataset_pubmed_tfidf\"\n",
    "with open(\"sent10_pubmed_tfidf.csv\", \"w\", encoding=\"utf-8\") as fwriter:\n",
    "    for file in os.listdir(f\"{test_path}\"):\n",
    "        with open(f\"{test_path}/{file}\") as freader:\n",
    "            next(freader)\n",
    "            for line in freader:\n",
    "                row = line.strip().split(\"\\t\")\n",
    "                sentence = f\"{row[0]}|{row[1]}\"\n",
    "                citation = row[3]\n",
    "                if sentence == sent and citation in ['18977449']:\n",
    "                    fwriter.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"{base_path}/test_dataset_pubmed_bm\"\n",
    "with open(\"sent10_pubmed_bm.csv\", \"w\", encoding=\"utf-8\") as fwriter:\n",
    "    for file in os.listdir(f\"{test_path}\"):\n",
    "        with open(f\"{test_path}/{file}\") as freader:\n",
    "            next(freader)\n",
    "            for line in freader:\n",
    "                row = line.strip().split(\"\\t\")\n",
    "                sentence = f\"{row[0]}|{row[1]}\"\n",
    "                citation = row[3]\n",
    "                if sentence == sent and citation in ['18977449']:\n",
    "                    fwriter.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'include OR cellprofiler OR imagej OR bioimagexd OR icy OR omero OR ebimage'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' OR '.join(sent.split('|')[0].strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pubmed_bm[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ' OR '.join(sent.split('|')[0].strip().split())\n",
    "year = test_pubmed_bm[sent]['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, pmids = pubmedweb_search(query, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, pmids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output 100 sentences for search on Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [k for k in results_bm.keys() if (k in results_sql and k in results_tfidf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_top20 = []\n",
    "n = 0\n",
    "for sent in sents:\n",
    "    for cite, ranks in results_bm[sent].items():\n",
    "        if len(ranks) == 1 and ranks[0][0] <= 20:\n",
    "            if cite in results_sql[sent] and results_sql[sent][cite][0][0] <= 20:\n",
    "                if cite in results_tfidf[sent] and results_tfidf[sent][cite][0][0] <= 20:\n",
    "                    sents_top20.append((sent, cite))\n",
    "                    n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11145\n"
     ]
    }
   ],
   "source": [
    "# sentences with citation in top 20 search results\n",
    "sents_top20 = []\n",
    "n = 0\n",
    "for sent in sents:\n",
    "    for cite, ranks in results_bm[sent].items():\n",
    "        if cite in results_sql[sent] and cite in results_tfidf[sent]:\n",
    "            sents_top20.append((sent, cite))\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(13)\n",
    "with open(\"sentences_for_google_scholar_search.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    fwriter = csv.writer(f)\n",
    "    fwriter.writerow(['sent_pmid', 'sentence', 'sent_pub_year', 'citation_pmid', 'citation_title', 'mbm_search_rank', 'tfidf_search_rank', 'bm_search_rank', 'gs_search_link', 'gs_search_link_or'])\n",
    "    for sent in random.sample(sents_top20, 100):\n",
    "        cite = sent[1]\n",
    "        pubmed_url = f\"https://pubmed.ncbi.nlm.nih.gov/{cite}/\"\n",
    "        soup = BeautifulSoup(get_page(pubmed_url), 'xml')\n",
    "        title = soup.find('h1', attrs={'class':'heading-title'}).text.strip()\n",
    "        sent = sent[0]\n",
    "        pmid = sent.split('|')[1]\n",
    "        txt = sent.split('|')[0]\n",
    "        query = ' OR '.join(sent.split('|')[0].strip().split())\n",
    "        year = test_pubmed_bm[sent]['year']\n",
    "        ggs_url = 'https://scholar.google.com/scholar'\n",
    "        ggs_url_txt = ggs_url + f'?q=site:pubmed.ncbi.nlm.nih.gov {txt}'\n",
    "        ggs_url_or = ggs_url + f'?q=site:pubmed.ncbi.nlm.nih.gov {query}'\n",
    "        ggs_url_txt += f'&hl=en&as_sdt=0,10&as_ylo=1977&as_yhi={year}'\n",
    "        ggs_url_or += f'&hl=en&as_sdt=0,10&as_ylo=1977&as_yhi={year}'\n",
    "        fwriter.writerow([pmid, txt, year, cite, title, results_sql[sent][cite][0][0], results_tfidf[sent][cite][0][0], results_bm[sent][cite][0][0], ggs_url_txt, ggs_url_or])\n",
    "#         print(pmid, txt, year, cite, title, results_sql[sent][cite][0][0], results_tfidf[sent][cite][0][0], results_bm[sent][cite][0][0], ggs_url_txt, ggs_url_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1)]\t[(4, 1)]\t[(7, 1)]\n",
      "[(2, 121)]\t[(3, 157)]\t[(230, 25)]\n",
      "[(1, 161)]\t[(4, 178)]\t[(20, 23)]\n",
      "[(1, 1)]\t[(448, 1)]\t[(360, 1)]\n",
      "[(183, 10)]\t[(146, 4)]\t[(3, 6)]\n",
      "[(217, 347)]\t[(23, 352)]\t[(249, 294)]\n",
      "[(1, 1)]\t[(2, 1)]\t[(4, 1)]\n",
      "[(58, 2)]\t[(458, 1)]\t[(138, 2)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(5, 1)]\n",
      "[(78, 150)]\t[(303, 250)]\t[(890, 209)]\n",
      "[(69, 17)]\t[(1, 147)]\t[(2, 2)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(2, 1)]\n",
      "[(2, 6)]\t[(2, 32)]\t[(3, 3)]\n",
      "[(1, 1)]\t[(1, 2)]\t[(6, 1)]\n",
      "[(3, 1)]\t[(496, 1)]\t[(260, 1)]\n",
      "[(13, 47)]\t[(282, 32)]\t[(29, 157)]\n",
      "[(348, 19)]\t[(67, 33)]\t[(97, 9)]\n",
      "[(1, 481)]\t[(1, 43)]\t[(5, 1)]\n",
      "[(1, 1)]\t[(2, 1)]\t[(21, 1)]\n",
      "[(51, 18)]\t[(4, 20)]\t[(322, 9)]\n",
      "[(2, 6)]\t[(10, 3)]\t[(103, 2)]\n",
      "[(11, 19)]\t[(68, 13)]\t[(474, 8)]\n",
      "[(4, 67)]\t[(6, 189)]\t[(379, 109)]\n",
      "[(9, 2)]\t[(9, 13)]\t[(769, 4)]\n",
      "[(4, 1)]\t[(5, 9)]\t[(16, 2)]\n",
      "[(1, 3)]\t[(859, 4)]\t[(40, 3)]\n",
      "[(10, 1)]\t[(1, 1)]\t[(659, 1)]\n",
      "[(1, 1)]\t[(2, 1)]\t[(42, 1)]\n",
      "[(6, 10)]\t[(4, 15)]\t[(52, 1)]\n",
      "[(59, 2)]\t[(60, 5)]\t[(4, 2)]\n",
      "[(1, 9)]\t[(9, 10)]\t[(7, 8)]\n",
      "[(8, 193)]\t[(7, 272)]\t[(181, 167)]\n",
      "[(1, 1)]\t[(1, 2)]\t[(235, 1)]\n",
      "[(23, 1)]\t[(2, 2)]\t[(16, 1)]\n",
      "[(12, 26)]\t[(11, 111)]\t[(622, 22)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(316, 1)]\n",
      "[(1, 6)]\t[(3, 5)]\t[(3, 14)]\n",
      "[(137, 17)]\t[(1, 41)]\t[(18, 11)]\n",
      "[(1, 13)]\t[(64, 13)]\t[(11, 8)]\n",
      "[(4, 1)]\t[(233, 1)]\t[(105, 1)]\n",
      "[(2, 1)]\t[(605, 1)]\t[(9, 1)]\n",
      "[(667, 24)]\t[(100, 13)]\t[(210, 11)]\n",
      "[(1, 2)]\t[(3, 2)]\t[(5, 1)]\n",
      "[(27, 19)]\t[(7, 16)]\t[(535, 10)]\n",
      "[(114, 59)]\t[(63, 57)]\t[(241, 67)]\n",
      "[(2, 1)]\t[(1, 1)]\t[(130, 1)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(340, 1)]\n",
      "[(11, 1)]\t[(1, 1)]\t[(7, 1)]\n",
      "[(2, 1)]\t[(3, 1)]\t[(9, 1)]\n",
      "[(1, 1)]\t[(2, 1)]\t[(38, 1)]\n",
      "[(28, 3)]\t[(97, 8)]\t[(125, 6)]\n",
      "[(1, 106)]\t[(20, 117)]\t[(294, 3)]\n",
      "[(1, 1)]\t[(5, 1)]\t[(11, 1)]\n",
      "[(37, 155)]\t[(677, 104)]\t[(200, 234)]\n",
      "[(171, 72)]\t[(218, 85)]\t[(111, 57)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(33, 1)]\n",
      "[(4, 1)]\t[(38, 1)]\t[(2, 1)]\n",
      "[(9, 85)]\t[(4, 356)]\t[(9, 7)]\n",
      "[(6, 2)]\t[(1, 109)]\t[(2, 1)]\n",
      "[(1, 1)]\t[(33, 1)]\t[(5, 1)]\n",
      "[(81, 24)]\t[(529, 28)]\t[(229, 9)]\n",
      "[(88, 2)]\t[(183, 5)]\t[(140, 6)]\n",
      "[(56, 18)]\t[(14, 36)]\t[(28, 16)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(2, 1)]\n",
      "[(1, 218)]\t[(26, 1248)]\t[(422, 39)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(5, 1)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(15, 1)]\n",
      "[(39, 1)]\t[(1, 1)]\t[(187, 1)]\n",
      "[(1, 1)]\t[(1, 1)]\t[(1, 1)]\n",
      "[(1, 2)]\t[(2, 3)]\t[(372, 3)]\n",
      "[(59, 1)]\t[(2, 1)]\t[(36, 2)]\n",
      "[(1, 1)]\t[(2, 1)]\t[(323, 1)]\n",
      "[(1, 1)]\t[(10, 1)]\t[(4, 4)]\n",
      "[(51, 60)]\t[(220, 131)]\t[(64, 48)]\n",
      "[(407, 11)]\t[(75, 21)]\t[(12, 42)]\n",
      "[(26, 1)]\t[(269, 1)]\t[(71, 1)]\n",
      "[(105, 6)]\t[(33, 4)]\t[(63, 8)]\n",
      "[(321, 62)]\t[(54, 64)]\t[(209, 83)]\n",
      "[(42, 1)]\t[(268, 1)]\t[(277, 1)]\n",
      "[(11, 3)]\t[(1, 3)]\t[(1, 6)]\n",
      "[(14, 3)]\t[(4, 2)]\t[(46, 4)]\n",
      "[(8, 6)]\t[(1, 2)]\t[(47, 3)]\n",
      "[(156, 19)]\t[(402, 14)]\t[(5, 7)]\n",
      "[(3, 266)]\t[(2, 63)]\t[(4, 22)]\n",
      "[(1, 51)]\t[(2, 81)]\t[(43, 12)]\n",
      "[(4, 1)]\t[(1, 1)]\t[(6, 1)]\n",
      "[(1, 40)]\t[(1, 41)]\t[(14, 8)]\n",
      "[(3, 1)]\t[(3, 1)]\t[(7, 2)]\n",
      "[(710, 4)]\t[(14, 4)]\t[(236, 6)]\n",
      "[(6, 20)]\t[(369, 44)]\t[(38, 3)]\n",
      "[(6, 1)]\t[(9, 1)]\t[(13, 1)]\n",
      "[(1, 35)]\t[(7, 24)]\t[(6, 5)]\n",
      "[(46, 193)]\t[(10, 176)]\t[(79, 60)]\n",
      "[(51, 6)]\t[(29, 8)]\t[(7, 97)]\n",
      "[(27, 11)]\t[(21, 9)]\t[(7, 11)]\n",
      "[(408, 1)]\t[(1, 1)]\t[(136, 7)]\n",
      "[(3, 1)]\t[(1, 2)]\t[(2, 1)]\n",
      "[(147, 37)]\t[(316, 27)]\t[(609, 66)]\n",
      "[(1, 2)]\t[(1, 3)]\t[(271, 2)]\n",
      "[(2, 1)]\t[(374, 1)]\t[(224, 1)]\n",
      "66\t64\t43\n",
      "35\t26\t2\n",
      "75\t68\t81\n",
      "41\t37\t40\n"
     ]
    }
   ],
   "source": [
    "top1_sql, top1_tfidf, top1_bm = 0, 0, 0\n",
    "top20_sql, top20_tfidf, top20_bm = 0, 0, 0\n",
    "rr_top1_sql, rr_top1_tfidf, rr_top1_bm = 0, 0, 0\n",
    "rr_top20_sql, rr_top20_tfidf, rr_top20_bm = 0, 0, 0\n",
    "with open(\"sentences_for_google_scholar_search.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    freader = csv.reader(f)\n",
    "    next(freader)\n",
    "    for row in freader:\n",
    "        sent = f\"{row[1]}|{row[0]}\"\n",
    "        cite = row[3]\n",
    "        \n",
    "        if results_sql[sent][cite][0][0] == 1: top1_sql += 1\n",
    "        if results_sql[sent][cite][0][1] == 1: rr_top1_sql += 1\n",
    "        if results_sql[sent][cite][0][0] <= 20: top20_sql += 1\n",
    "        if results_sql[sent][cite][0][1] <= 20: rr_top20_sql += 1\n",
    "        \n",
    "        if results_tfidf[sent][cite][0][0] == 1: top1_tfidf += 1\n",
    "        if results_tfidf[sent][cite][0][1] == 1: rr_top1_tfidf += 1\n",
    "        if results_tfidf[sent][cite][0][0] <= 20: top20_tfidf += 1\n",
    "        if results_tfidf[sent][cite][0][1] <= 20: rr_top20_tfidf += 1\n",
    "        \n",
    "        if results_bm[sent][cite][0][0] == 1: top1_bm += 1\n",
    "        if results_bm[sent][cite][0][1] == 1: rr_top1_bm += 1\n",
    "        if results_bm[sent][cite][0][0] <= 20: top20_bm += 1\n",
    "        if results_bm[sent][cite][0][1] <= 20: rr_top20_bm += 1\n",
    "        \n",
    "        print(f\"{results_sql[sent][cite]}\\t{results_tfidf[sent][cite]}\\t{results_bm[sent][cite]}\")\n",
    "print(f\"{top20_sql}\\t{top20_tfidf}\\t{top20_bm}\")\n",
    "print(f\"{top1_sql}\\t{top1_tfidf}\\t{top1_bm}\")\n",
    "print(f\"{rr_top20_sql}\\t{rr_top20_tfidf}\\t{rr_top20_bm}\")\n",
    "print(f\"{rr_top1_sql}\\t{rr_top1_tfidf}\\t{rr_top1_bm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
