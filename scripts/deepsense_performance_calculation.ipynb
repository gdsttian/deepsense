{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSense: a Deep Learning Method for Full-sentence Search of Biomedical Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './project/src_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_stats(data_file):\n",
    "    sents = set()\n",
    "    p = 0\n",
    "    n = 0\n",
    "    with open(data_file) as f:\n",
    "        next(f)\n",
    "        for row in f:\n",
    "            row = row.strip().split('\\t')\n",
    "            sents.add(f\"{row[0]}|{row[1]}\")\n",
    "            if row[-1] == '1': p += 1\n",
    "            if row[-1] == '0': n += 1\n",
    "    print(f\"{'Total Sentences':30}{len(sents)}\\n{'Positive Instances':30}{p}\")\n",
    "    print(f\"{'Negative Instances':30}{n}\\n{'Total Instances':30}{p+n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset: input/train_sentences.tsv\n",
    "\n",
    "Some sentences have more than 1 citations, so have more than 1 positive instance, resulting in 936,591 positive instances. For each positive instance, sample 2 negative instances, some negative instances may be duplicated, resulting in 1,870,387 negative instances after removal of the duplicated instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences               854101\n",
      "Positive Instances            936591\n",
      "Negative Instances            1870387\n",
      "Total Instances               2806978\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{base_path}/input/train_sentences.tsv\"\n",
    "get_train_val_stats(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Dataset: input/valid_sentences.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences               145455\n",
      "Positive Instances            148269\n",
      "Negative Instances            296128\n",
      "Total Instances               444397\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{base_path}/input/valid_sentences.tsv\"\n",
    "get_train_val_stats(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Datasets\n",
    "\n",
    "- SQL_BM25: case_SQL_testing_final_complete\n",
    "- PubMed_TFIDF: case_PubMed_testing_final_complete\n",
    "- PubMed_BM: case_PubMed_BM_testing_final_complete\n",
    "- Google_Scholar: case_Google_scholar_testing_final_complete\n",
    "\n",
    "Test datasets development process:\n",
    "\n",
    "- Develop citing sentence and cited paper pairs from PMC articles (code not available, original data not available)\n",
    "  - Output data format: citing_sentence, citing_sentence_pmid, cited_paper_pmid, (citing_sentence_original_text)\n",
    "- Acquire search returns for each citing sentence query\n",
    "  - Codes: create_test_search_PubMed.py <- PM_function.py/create_data_PubMed\n",
    "  - Output data format: citing_sentence, citing_sentence_pmid, search_returned_paper_pmid, cited_paper_pmid\n",
    "- Create final test datasets\n",
    "  - Code: create_PM_final_test.py\n",
    "\n",
    "Issues:\n",
    "\n",
    "- Exist in creating final test datasets (Code: create_PM_final_test.py)\n",
    "  - Incomplete information dictionary of total pubmed papers\n",
    "    - Forward search of citing sentence paper publishing year when its pmid not in the dictionary\n",
    "    - Skip search returned papers when their pmids not in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96950"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test sentences record\n",
    "test_sentences_records_all = json.load(open(f\"{base_path}/test_sentences_records.json\"))\n",
    "len(test_sentences_records_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with 1 publishing year        96950\n",
      "Sentences with >1 publishing year       0\n",
      "Sentences with 1+ citations             4703\n",
      "Sentences with only 1 citation          92247\n"
     ]
    }
   ],
   "source": [
    "# Check publishing year of test sentences and keep only sentences with 1 citation\n",
    "m, n, p = 0, 0, 0\n",
    "test_sentences_records = {}\n",
    "for k, v in test_sentences_records_all.items():\n",
    "    if len(v['year']) > 1: m += 1\n",
    "    if len(v['year']) == 1: n += 1\n",
    "    if len(v['citations']) > 1:\n",
    "        p += 1\n",
    "    else:\n",
    "        test_sentences_records[k] = v\n",
    "print(f\"{'Sentences with 1 publishing year':40}{n}\\n{'Sentences with >1 publishing year':40}{m}\")\n",
    "print(f\"{'Sentences with 1+ citations':40}{p}\")\n",
    "print(f\"{'Sentences with only 1 citation':40}{len(test_sentences_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations               92247\n",
      "Total unique cited papers     82639\n",
      "Sentences with >1 citations   0\n"
     ]
    }
   ],
   "source": [
    "# check citations of test sentences\n",
    "m, n = 0, 0\n",
    "cites = set()\n",
    "for v in test_sentences_records.values():\n",
    "    n += len(v['citations'])\n",
    "    if len(v['citations']) > 1: m += 1\n",
    "    for cite in v['citations']:\n",
    "        cites.add(cite)\n",
    "print(f\"{'Total citations':30}{n}\\n{'Total unique cited papers':30}{len(cites)}\\n{'Sentences with >1 citations':30}{m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with <5 tokens           217\n",
      "Sentences with >50 tokens          1273\n",
      "Sentences retained for test        90757\n"
     ]
    }
   ],
   "source": [
    "# retain only sentences with 5+ and 50- tokens for final test\n",
    "test_sentences = {}\n",
    "m, n = 0, 0\n",
    "# for k, v in test_sentences_records_all.items():\n",
    "for k, v in test_sentences_records.items():\n",
    "    if len(k.split('|')[0].split()) < 5:\n",
    "        m += 1\n",
    "    elif len(k.split('|')[0].split()) > 50:\n",
    "        n += 1\n",
    "    else:\n",
    "        test_sentences[k] = v\n",
    "print(f\"{'Sentences with <5 tokens':35}{m}\\n{'Sentences with >50 tokens':35}{n}\")\n",
    "print(f\"{'Sentences retained for test':35}{len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations               90757\n",
      "Total unique cited papers     81411\n",
      "Sentences with >1 citations   0\n"
     ]
    }
   ],
   "source": [
    "# check citations of final test sentences\n",
    "m, n = 0, 0\n",
    "cites = set()\n",
    "more_cites_sentences = {}\n",
    "for k, v in test_sentences.items():\n",
    "    n += len(v['citations'])\n",
    "    if len(v['citations']) > 1:\n",
    "        more_cites_sentences[k] = v\n",
    "        m += 1\n",
    "    for cite in v['citations']:\n",
    "        cites.add(cite)\n",
    "print(f\"{'Total citations':30}{n}\\n{'Total unique cited papers':30}{len(cites)}\\n{'Sentences with >1 citations':30}{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for stats calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_stats(test_path, test_sentences_records):\n",
    "    sents = set()\n",
    "    extra_sents = set()\n",
    "    cites = set()\n",
    "    extra_cites = set()\n",
    "    n, m = 0, 0\n",
    "    for file in os.listdir(f\"{test_path}\"):\n",
    "        with open(f\"{test_path}/{file}\") as ifile:\n",
    "            next(ifile)\n",
    "            for row in ifile:\n",
    "                row = row.strip().split(\"\\t\")\n",
    "                sentence = f\"{row[0]}|{row[1]}\"\n",
    "                citation = row[3]\n",
    "                if sentence in test_sentences_records:\n",
    "                    sents.add(sentence)\n",
    "                    cites.add(citation)\n",
    "                    n += 1\n",
    "                else:\n",
    "                    extra_sents.add(sentence)\n",
    "                    extra_cites.add(citation)\n",
    "                    m += 1 \n",
    "                    \n",
    "    #             if citation in test_sentences_records[sentence]['citations']: m += 1\n",
    "    print(f\"Test Sentences: {len(sents):12}\\tExtra Sentences: {len(extra_sents)}\")\n",
    "    print(f\"Test Citations: {len(cites):12}\\tExtra Citations: {len(extra_cites.difference(cites))}\")\n",
    "    print(f\"Test Instances: {n:12}\\tExtra Instances: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_stats(pred_path, test_sentences_records):\n",
    "    sents = set()\n",
    "    extra_sents = set()\n",
    "    cites = set()\n",
    "    extra_cites = set()\n",
    "    n, m = 0, 0\n",
    "    for file in os.listdir(f\"{pred_path}\"):\n",
    "        with open(f\"{pred_path}/{file}\") as ifile:\n",
    "            next(ifile)\n",
    "            for row in ifile:\n",
    "                row = row.strip().split(\"\\t\")\n",
    "                sentence = '|'.join(row[0].split('|')[:2])\n",
    "                citation = row[1]\n",
    "                if sentence in test_sentences_records:\n",
    "                    sents.add(sentence)\n",
    "                    cites.add(citation)\n",
    "                    n += 1\n",
    "                else:\n",
    "                    extra_sents.add(sentence)\n",
    "                    extra_cites.add(citation)\n",
    "                    m += 1\n",
    "    #             if citation in test_sentences_records[sentence]['citations']: m += 1\n",
    "    print(f\"Test Sentences: {len(sents):12}\\tExtra Sentences: {len(extra_sents)}\")\n",
    "    print(f\"Test Citations: {len(cites):12}\\tExtra Citations: {len(extra_cites.difference(cites))}\")\n",
    "    print(f\"Test Instances: {n:12}\\tExtra Instances: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_results(pred_path, test_sentences_records):\n",
    "    pred_results = {}\n",
    "    serank_top1, serank_top10, serank_top20, serank_top100 = 0, 0, 0, 0\n",
    "    serr_top10, serr_top20, serr_top100 = [], [], []\n",
    "    rerank_top1, rerank_top10, rerank_top20, rerank_top100 = 0, 0, 0, 0\n",
    "    rerr_top10, rerr_top20, rerr_top100 = [], [], []\n",
    "    better_serank, tie_rank, better_rerank = 0, 0, 0\n",
    "    num_dup_citations = 0\n",
    "    for file in os.listdir(pred_path):\n",
    "        with open(f\"{pred_path}/{file}\") as ifile:\n",
    "            next(ifile)\n",
    "            for row in ifile:\n",
    "                row = row.strip().split(\"\\t\")\n",
    "                sentence = '|'.join(row[0].split('|')[:2])\n",
    "                citation = row[1]\n",
    "                serank = int(row[2])\n",
    "                rerank = int(row[3])\n",
    "                if sentence in test_sentences_records:\n",
    "                    if citation in test_sentences_records[sentence]['citations']:\n",
    "                        pred_results[sentence] = pred_results.get(sentence, {})\n",
    "                        if citation not in pred_results[sentence]:\n",
    "                            pred_results[sentence][citation] = pred_results[sentence].get(citation, [])\n",
    "                            pred_results[sentence][citation].append((serank, rerank))\n",
    "                            if serank == 1: serank_top1 += 1\n",
    "                            if serank <= 10:\n",
    "                                serank_top10 += 1\n",
    "                                serr_top10.append(1/serank)\n",
    "                            if serank <= 20:\n",
    "                                serank_top20 += 1\n",
    "                                serr_top20.append(1/serank)\n",
    "                            if serank <= 100:\n",
    "                                serank_top100 += 1\n",
    "                                serr_top100.append(1/serank)\n",
    "\n",
    "                            if rerank == 1: rerank_top1 += 1\n",
    "                            if rerank <= 10:\n",
    "                                rerank_top10 += 1\n",
    "                                rerr_top10.append(1/rerank)\n",
    "                            if rerank <= 20:\n",
    "                                rerank_top20 += 1\n",
    "                                rerr_top20.append(1/rerank)\n",
    "                            if rerank <= 100:\n",
    "                                rerank_top100 += 1\n",
    "                                rerr_top100.append(1/rerank)\n",
    "\n",
    "                            if serank < rerank: better_serank += 1\n",
    "                            if serank == rerank: tie_rank += 1\n",
    "                            if rerank < serank: better_rerank += 1\n",
    "                        else: num_dup_citations += 1\n",
    "    \n",
    "    print(f\"{'Rank':20}\\t{'Top1':8}\\t{'Top10':8}\\t{'Top20':8}\\t{'Top100'}\")\n",
    "    print(f\"{80*'-'}\")\n",
    "    print(f\"{'Search':20}\\t{serank_top1:<8}\\t{serank_top10:<8}\\t{serank_top20:<8}\\t{serank_top100}\")\n",
    "    print(f\"{'Search R@k':20}\\t{serank_top1/len(pred_results):<8.4f}\\t{serank_top10/len(pred_results):<8.4f}\\t{serank_top20/len(pred_results):<8.4f}\\t{serank_top100/len(pred_results):<8.4f}\")\n",
    "    print(f\"{'Search MAP':20}\\t{serank_top1/len(pred_results):<8.4f}\\t{serank_top10*1/10/len(pred_results):<8.4f}\\t{serank_top20*1/20/len(pred_results):<8.4f}\\t{serank_top100*1/100/len(pred_results):<8.4f}\")\n",
    "    print(f\"{'Search MRR':20}\\t{serank_top1/len(pred_results):<8.4f}\\t{sum(serr_top10)/len(pred_results):<8.4f}\\t{sum(serr_top20)/len(pred_results):<8.4f}\\t{sum(serr_top100)/len(pred_results):<8.4f}\")\n",
    "    print()\n",
    "    print(f\"{'Rerank':20}\\t{rerank_top1:<8}\\t{rerank_top10:<8}\\t{rerank_top20:<8}\\t{rerank_top100}\")\n",
    "    print(f\"{'Rerank R@k':20}\\t{rerank_top1/len(pred_results):<8.4f}\\t{rerank_top10/len(pred_results):<8.4f}\\t{rerank_top20/len(pred_results):<8.4f}\\t{rerank_top100/len(pred_results):<8.4f}\")\n",
    "    print(f\"{'Rerank MAP':20}\\t{rerank_top1/len(pred_results):<8.4f}\\t{rerank_top10*1/10/len(pred_results):<8.4f}\\t{rerank_top20*1/20/len(pred_results):<8.4f}\\t{rerank_top100*1/100/len(pred_results):<8.4f}\")\n",
    "    print(f\"{'Rerank MRR':20}\\t{rerank_top1/len(pred_results):<8.4f}\\t{sum(rerr_top10)/len(pred_results):<8.4f}\\t{sum(rerr_top20)/len(pred_results):<8.4f}\\t{sum(rerr_top100)/len(pred_results):<8.4f}\")\n",
    "    print()\n",
    "    print(f\"{'Duplicated citations':20}\\t{num_dup_citations}\")\n",
    "    print(f\"{'Search Win':20}\\t{better_serank}\")\n",
    "    print(f\"{'Tie':20}\\t{tie_rank}\")\n",
    "    print(f\"{'Rerank Improvement':20}\\t{better_rerank}\")\n",
    "    \n",
    "    return pred_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results: SQL_BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        90757\tExtra Sentences: 6457\n",
      "Test Citations:        81411\tExtra Citations: 9514\n",
      "Test Instances:     90924838\tExtra Instances: 11627247\n"
     ]
    }
   ],
   "source": [
    "test_path = f\"{base_path}/test_dataset_sql_bm25\"\n",
    "get_test_stats(test_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        90757\tExtra Sentences: 6457\n",
      "Test Citations:        81411\tExtra Citations: 9514\n",
      "Test Instances:        90764\tExtra Instances: 11629\n",
      "\n",
      "\n",
      "\n",
      "Rank                \tTop1    \tTop10   \tTop20   \tTop100\n",
      "--------------------------------------------------------------------------------\n",
      "Search              \t17898   \t38151   \t44957   \t62609\n",
      "Search R@k          \t0.1972  \t0.4204  \t0.4954  \t0.6899  \n",
      "Search MAP          \t0.1972  \t0.0420  \t0.0248  \t0.0069  \n",
      "Search MRR          \t0.1972  \t0.2632  \t0.2684  \t0.2731  \n",
      "\n",
      "Rerank              \t23649   \t52058   \t61132   \t79830\n",
      "Rerank R@k          \t0.2606  \t0.5736  \t0.6736  \t0.8796  \n",
      "Rerank MAP          \t0.2606  \t0.0574  \t0.0337  \t0.0088  \n",
      "Rerank MRR          \t0.2606  \t0.3523  \t0.3593  \t0.3645  \n",
      "\n",
      "Duplicated citations\t7\n",
      "Search Win          \t24897\n",
      "Tie                 \t12568\n",
      "Rerank Improvement  \t53292\n"
     ]
    }
   ],
   "source": [
    "# test results of sentences with SQL_BM25 top 500 search returns (New)\n",
    "pred_path = f\"{base_path}/src_model_full_sentence/test_results_sql_bm25\"\n",
    "get_pred_stats(pred_path, test_sentences)\n",
    "print('\\n\\n')\n",
    "results_sql = get_pred_results(pred_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of citations search returns broken into 2 files\n",
    "n = 0\n",
    "sentences_in_2_files = {}\n",
    "for k, v in results_sql.items():\n",
    "    for ck, cv in v.items():\n",
    "        if len(cv) > 1:\n",
    "            sentences_in_2_files[k] = v\n",
    "            print(k, v)\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90757"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90757, 24897, 90757, 1, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serank = []\n",
    "better_serank = 0\n",
    "for k, v in results_sql.items():\n",
    "    for ck, cv in v.items():\n",
    "        serank.append(cv[0][0])\n",
    "        if cv[0][0] < cv[0][1]: better_serank += 1\n",
    "len(results_sql), better_serank, len(serank), min(serank), max(serank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results: PubMed_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        90757\tExtra Sentences: 6193\n",
      "Test Citations:        81411\tExtra Citations: 9258\n",
      "Test Instances:     89029754\tExtra Instances: 11098315\n"
     ]
    }
   ],
   "source": [
    "test_path = f\"{base_path}/test_dataset_pubmed_tfidf\"\n",
    "get_test_stats(test_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        57123\tExtra Sentences: 4489\n",
      "Test Citations:        52020\tExtra Citations: 5716\n",
      "Test Instances:        57125\tExtra Instances: 6829\n",
      "\n",
      "\n",
      "\n",
      "Rank                \tTop1    \tTop10   \tTop20   \tTop100\n",
      "--------------------------------------------------------------------------------\n",
      "Search              \t8915    \t20951   \t25262   \t37033\n",
      "Search R@k          \t0.1561  \t0.3668  \t0.4422  \t0.6483  \n",
      "Search MAP          \t0.1561  \t0.0367  \t0.0221  \t0.0065  \n",
      "Search MRR          \t0.1561  \t0.2177  \t0.2228  \t0.2278  \n",
      "\n",
      "Rerank              \t16777   \t35103   \t40260   \t50434\n",
      "Rerank R@k          \t0.2937  \t0.6145  \t0.7048  \t0.8829  \n",
      "Rerank MAP          \t0.2937  \t0.0615  \t0.0352  \t0.0088  \n",
      "Rerank MRR          \t0.2937  \t0.3898  \t0.3961  \t0.4006  \n",
      "\n",
      "Duplicated citations\t2\n",
      "Search Win          \t13900\n",
      "Tie                 \t6164\n",
      "Rerank Improvement  \t37059\n"
     ]
    }
   ],
   "source": [
    "# test results of sentences with PubMed TFIDF top 500 search returns\n",
    "pred_path = f\"{base_path}/src_model_full_sentence/test_results_pubmed_tfidf\"\n",
    "get_pred_stats(pred_path, test_sentences)\n",
    "print('\\n\\n')\n",
    "results_tfidf = get_pred_results(pred_path, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of citations search returns broken into 2 files\n",
    "n = 0\n",
    "for k, v in results_tfidf.items():\n",
    "    for ck, cv in v.items():\n",
    "        if len(cv) > 1:\n",
    "            print(k, v)\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57123, 13900, 57123, 1, 998)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serank = []\n",
    "better_serank = 0\n",
    "for k, v in results_tfidf.items():\n",
    "    for ck, cv in v.items():\n",
    "        serank.append(cv[0][0])\n",
    "        if cv[0][0] < cv[0][1]: better_serank += 1\n",
    "len(results_tfidf), better_serank, len(serank), min(serank), max(serank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \tTop1    \tTop10   \tTop20   \tTop100  \n",
      "------------------------------------------------------------------------------------------\n",
      "Sentences in SQL/TFIDF        \t57123   \t57123   \t57123   \n",
      "SQL Search Results            \t15755   \t31132   \t35567   \t45504   \n",
      "SQL Search Results R@k        \t0.2758  \t0.5450  \t0.6226  \t0.7966  \n",
      "SQL Search Results MAP        \t0.2758  \t0.0545  \t0.0311  \t0.0080  \n",
      "SQL Search Results MRR        \t0.2758  \t0.3578  \t0.3632  \t0.3675  \n",
      "\n",
      "SQL Rerank Results            \t19204   \t37890   \t42911   \t52283   \n",
      "SQL Rerank Results R@k        \t0.3362  \t0.6633  \t0.7512  \t0.9153  \n",
      "SQL Rerank Results MAP        \t0.3362  \t0.0663  \t0.0376  \t0.0092  \n",
      "SQL Rerank Results MRR        \t0.3362  \t0.4356  \t0.4417  \t0.4459  \n",
      "\n",
      "TFIDF Search Results          \t8915    \t20951   \t25262   \t37033   \n",
      "TFIDF Search Results R@k      \t0.1561  \t0.3668  \t0.4422  \t0.6483  \n",
      "TFIDF Search Results MAP      \t0.1561  \t0.0367  \t0.0221  \t0.0065  \n",
      "TFIDF Search Results MRR      \t0.1561  \t0.2177  \t0.2228  \t0.2278  \n",
      "\n",
      "TFIDF Rerank Results          \t16777   \t35103   \t40260   \t50434   \n",
      "TFIDF Rerank Results R@k      \t0.2937  \t0.6145  \t0.7048  \t0.8829  \n",
      "TFIDF Rerank Results MAP      \t0.2937  \t0.0615  \t0.0352  \t0.0088  \n",
      "TFIDF Rerank Results MRR      \t0.2937  \t0.3898  \t0.3961  \t0.4006  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_sql, m = 0, 0\n",
    "sents = set()\n",
    "n_sql_se_1, n_sql_se_10, n_sql_se_20, n_sql_se_100 = 0, 0, 0, 0\n",
    "rr_sql_se_10, rr_sql_se_20, rr_sql_se_100 = [], [], []\n",
    "n_sql_re_1, n_sql_re_10, n_sql_re_20, n_sql_re_100 = 0, 0, 0, 0\n",
    "rr_sql_re_10, rr_sql_re_20, rr_sql_re_100 = [], [], []\n",
    "\n",
    "n_tfidf_se_1, n_tfidf_se_10, n_tfidf_se_20, n_tfidf_se_100 = 0, 0, 0, 0\n",
    "rr_tfidf_se_10, rr_tfidf_se_20, rr_tfidf_se_100 = [], [], []\n",
    "n_tfidf_re_1, n_tfidf_re_10, n_tfidf_re_20, n_tfidf_re_100 = 0, 0, 0, 0\n",
    "rr_tfidf_re_10, rr_tfidf_re_20, rr_tfidf_re_100 = [], [], []\n",
    "\n",
    "for k,v in results_tfidf.items():\n",
    "    if k in results_sql:\n",
    "        m += 1\n",
    "        for i in v:\n",
    "            if i in results_sql[k]:\n",
    "                n_sql += 1\n",
    "                sents.add(k)\n",
    "                if results_sql[k][i][0][0] == 1: n_sql_se_1 += 1\n",
    "                if results_sql[k][i][0][0] <= 10:\n",
    "                    n_sql_se_10 += 1\n",
    "                    rr_sql_se_10.append(1/results_sql[k][i][0][0])\n",
    "                if results_sql[k][i][0][0] <= 20:\n",
    "                    n_sql_se_20 += 1\n",
    "                    rr_sql_se_20.append(1/results_sql[k][i][0][0])\n",
    "                if results_sql[k][i][0][0] <= 100:\n",
    "                    n_sql_se_100 += 1\n",
    "                    rr_sql_se_100.append(1/results_sql[k][i][0][0])\n",
    "                \n",
    "                if results_sql[k][i][0][1] == 1: n_sql_re_1 += 1\n",
    "                if results_sql[k][i][0][1] <= 10:\n",
    "                    n_sql_re_10 += 1\n",
    "                    rr_sql_re_10.append(1/results_sql[k][i][0][1])\n",
    "                if results_sql[k][i][0][1] <= 20:\n",
    "                    n_sql_re_20 += 1\n",
    "                    rr_sql_re_20.append(1/results_sql[k][i][0][1])\n",
    "                if results_sql[k][i][0][1] <= 100:\n",
    "                    n_sql_re_100 += 1\n",
    "                    rr_sql_re_100.append(1/results_sql[k][i][0][1])\n",
    "                \n",
    "                if results_tfidf[k][i][0][0] == 1: n_tfidf_se_1 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 10:\n",
    "                    n_tfidf_se_10 += 1\n",
    "                    rr_tfidf_se_10.append(1/results_tfidf[k][i][0][0])\n",
    "                if results_tfidf[k][i][0][0] <= 20:\n",
    "                    n_tfidf_se_20 += 1\n",
    "                    rr_tfidf_se_20.append(1/results_tfidf[k][i][0][0])\n",
    "                if results_tfidf[k][i][0][0] <= 100:\n",
    "                    n_tfidf_se_100 += 1\n",
    "                    rr_tfidf_se_100.append(1/results_tfidf[k][i][0][0])\n",
    "                \n",
    "                if results_tfidf[k][i][0][1] == 1: n_tfidf_re_1 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 10:\n",
    "                    n_tfidf_re_10 += 1\n",
    "                    rr_tfidf_re_10.append(1/results_tfidf[k][i][0][1])\n",
    "                if results_tfidf[k][i][0][1] <= 20:\n",
    "                    n_tfidf_re_20 += 1\n",
    "                    rr_tfidf_re_20.append(1/results_tfidf[k][i][0][1])\n",
    "                if results_tfidf[k][i][0][1] <= 100:\n",
    "                    n_tfidf_re_100 += 1\n",
    "                    rr_tfidf_re_100.append(1/results_tfidf[k][i][0][1])\n",
    "\n",
    "print(f\"{' ':30}\\t{'Top1':8}\\t{'Top10':8}\\t{'Top20':8}\\t{'Top100':8}\")\n",
    "print(f\"{90*'-'}\")\n",
    "print(f\"{'Sentences in SQL/TFIDF':30}\\t{m:<8}\\t{len(sents):<8}\\t{n_sql:<8}\")\n",
    "print(f\"{'SQL Search Results':30}\\t{n_sql_se_1:<8}\\t{n_sql_se_10:<8}\\t{n_sql_se_20:<8}\\t{n_sql_se_100:<8}\")\n",
    "print(f\"{'SQL Search Results R@k':30}\\t{n_sql_se_1/n_sql:<8.4f}\\t{n_sql_se_10/n_sql:<8.4f}\\t{n_sql_se_20/n_sql:<8.4f}\\t{n_sql_se_100/n_sql:<8.4f}\")\n",
    "print(f\"{'SQL Search Results MAP':30}\\t{n_sql_se_1/n_sql:<8.4f}\\t{n_sql_se_10*1/10/n_sql:<8.4f}\\t{n_sql_se_20*1/20/n_sql:<8.4f}\\t{n_sql_se_100*1/100/n_sql:<8.4f}\")\n",
    "print(f\"{'SQL Search Results MRR':30}\\t{n_sql_se_1/n_sql:<8.4f}\\t{sum(rr_sql_se_10)/n_sql:<8.4f}\\t{sum(rr_sql_se_20)/n_sql:<8.4f}\\t{sum(rr_sql_se_100)/n_sql:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'SQL Rerank Results':30}\\t{n_sql_re_1:<8}\\t{n_sql_re_10:<8}\\t{n_sql_re_20:<8}\\t{n_sql_re_100:<8}\")\n",
    "print(f\"{'SQL Rerank Results R@k':30}\\t{n_sql_re_1/n_sql:<8.4f}\\t{n_sql_re_10/n_sql:<8.4f}\\t{n_sql_re_20/n_sql:<8.4f}\\t{n_sql_re_100/n_sql:<8.4f}\")\n",
    "print(f\"{'SQL Rerank Results MAP':30}\\t{n_sql_re_1/n_sql:<8.4f}\\t{n_sql_re_10*1/10/n_sql:<8.4f}\\t{n_sql_re_20*1/20/n_sql:<8.4f}\\t{n_sql_re_100*1/100/n_sql:<8.4f}\")\n",
    "print(f\"{'SQL Rerank Results MRR':30}\\t{n_sql_re_1/n_sql:<8.4f}\\t{sum(rr_sql_re_10)/n_sql:<8.4f}\\t{sum(rr_sql_re_20)/n_sql:<8.4f}\\t{sum(rr_sql_re_100)/n_sql:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Search Results':30}\\t{n_tfidf_se_1:<8}\\t{n_tfidf_se_10:<8}\\t{n_tfidf_se_20:<8}\\t{n_tfidf_se_100:<8}\")\n",
    "print(f\"{'TFIDF Search Results R@k':30}\\t{n_tfidf_se_1/n_sql:<8.4f}\\t{n_tfidf_se_10/n_sql:<8.4f}\\t{n_tfidf_se_20/n_sql:<8.4f}\\t{n_tfidf_se_100/n_sql:<8.4f}\")\n",
    "print(f\"{'TFIDF Search Results MAP':30}\\t{n_tfidf_se_1/n_sql:<8.4f}\\t{n_tfidf_se_10*1/10/n_sql:<8.4f}\\t{n_tfidf_se_20*1/20/n_sql:<8.4f}\\t{n_tfidf_se_100*1/100/n_sql:<8.4f}\")\n",
    "print(f\"{'TFIDF Search Results MRR':30}\\t{n_tfidf_se_1/n_sql:<8.4f}\\t{sum(rr_tfidf_se_10)/n_sql:<8.4f}\\t{sum(rr_tfidf_se_20)/n_sql:<8.4f}\\t{sum(rr_tfidf_se_100)/n_sql:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Rerank Results':30}\\t{n_tfidf_re_1:<8}\\t{n_tfidf_re_10:<8}\\t{n_tfidf_re_20:<8}\\t{n_tfidf_re_100:<8}\")\n",
    "print(f\"{'TFIDF Rerank Results R@k':30}\\t{n_tfidf_re_1/n_sql:<8.4f}\\t{n_tfidf_re_10/n_sql:<8.4f}\\t{n_tfidf_re_20/n_sql:<8.4f}\\t{n_tfidf_re_100/n_sql:<8.4f}\")\n",
    "print(f\"{'TFIDF Rerank Results MAP':30}\\t{n_tfidf_re_1/n_sql:<8.4f}\\t{n_tfidf_re_10*1/10/n_sql:<8.4f}\\t{n_tfidf_re_20*1/20/n_sql:<8.4f}\\t{n_tfidf_re_100*1/100/n_sql:<8.4f}\")\n",
    "print(f\"{'TFIDF Rerank Results MRR':30}\\t{n_tfidf_re_1/n_sql:<8.4f}\\t{sum(rr_tfidf_re_10)/n_sql:<8.4f}\\t{sum(rr_tfidf_re_20)/n_sql:<8.4f}\\t{sum(rr_tfidf_re_100)/n_sql:<8.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sql[k][i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results: PubMed_BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45115"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pubmed_bm = json.load(open('test_sents_pubmed_bm.json', 'r', encoding='utf-8'))\n",
    "len(test_pubmed_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentences                                             41120\n",
      "Total Citations                                             41120\n",
      "Sentences with Top 1000 Search Returns                      16824\n",
      "Total Citations for Sentences with Top 1000 Search Returns  16824\n"
     ]
    }
   ],
   "source": [
    "# pubmed_bm dataset stat\n",
    "top1000_sentences = {} # sentences with top 1000 search returns\n",
    "num_sentences = 0\n",
    "num_citations = 0 # total number of citations\n",
    "top1000_num_citations = 0 # total number of citations in sentences with top 1000 search returns\n",
    "for k, v in test_pubmed_bm.items():\n",
    "    if k in test_sentences:\n",
    "        num_sentences += 1\n",
    "        num_citations += len(v['citations'])\n",
    "        if len(v['pmids']) > 600:\n",
    "            top1000_sentences[k] = v\n",
    "            top1000_num_citations += len(v['citations'])\n",
    "print(f\"{'Total Sentences':60}{num_sentences}\")\n",
    "print(f\"{'Total Citations':60}{num_citations}\")\n",
    "print(f\"{'Sentences with Top 1000 Search Returns':60}{len(top1000_sentences)}\")\n",
    "print(f\"{'Total Citations for Sentences with Top 1000 Search Returns':60}{top1000_num_citations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        41120\tExtra Sentences: 3995\n",
      "Test Citations:        38835\tExtra Citations: 6999\n",
      "Test Instances:     27026803\tExtra Instances: 5207044\n"
     ]
    }
   ],
   "source": [
    "# test_path = f\"{base_path}/case_PubMed_BM_testing_final_complete\"\n",
    "test_path = f\"{base_path}/test_dataset_pubmed_bm\"\n",
    "get_test_stats(test_path, test_sentences) # top1000_sentences, test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        16824\tExtra Sentences: 28291\n",
      "Test Citations:        16390\tExtra Citations: 29444\n",
      "Test Instances:     14501168\tExtra Instances: 17732679\n"
     ]
    }
   ],
   "source": [
    "# test_path = f\"{base_path}/case_PubMed_BM_testing_final_complete\"\n",
    "test_path = f\"{base_path}/test_dataset_pubmed_bm\"\n",
    "get_test_stats(test_path, top1000_sentences) # top1000_sentences, test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentences:        10782\tExtra Sentences: 11468\n",
      "Test Citations:        10553\tExtra Citations: 11706\n",
      "Test Instances:        10782\tExtra Instances: 12494\n",
      "\n",
      "\n",
      "\n",
      "Rank                \tTop1    \tTop10   \tTop20   \tTop100\n",
      "--------------------------------------------------------------------------------\n",
      "Search              \t432     \t2892    \t3969    \t6447\n",
      "Search R@k          \t0.0401  \t0.2682  \t0.3681  \t0.5979  \n",
      "Search MAP          \t0.0401  \t0.0268  \t0.0184  \t0.0060  \n",
      "Search MRR          \t0.0401  \t0.0963  \t0.1032  \t0.1090  \n",
      "\n",
      "Rerank              \t4382    \t7698    \t8517    \t10031\n",
      "Rerank R@k          \t0.4064  \t0.7140  \t0.7899  \t0.9303  \n",
      "Rerank MAP          \t0.4064  \t0.0714  \t0.0395  \t0.0093  \n",
      "Rerank MRR          \t0.4064  \t0.5023  \t0.5076  \t0.5113  \n",
      "\n",
      "Duplicated citations\t0\n",
      "Search Win          \t1400\n",
      "Tie                 \t396\n",
      "Rerank Improvement  \t8986\n"
     ]
    }
   ],
   "source": [
    "# test results of sentences with PubMed BM top 500 search returns\n",
    "pred_path = f\"{base_path}/src_model_full_sentence/test_results_pubmed_bm\"\n",
    "get_pred_stats(pred_path, top1000_sentences) # top1000_sentences, test_sentences\n",
    "print('\\n\\n')\n",
    "results_bm = get_pred_results(pred_path, top1000_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for k, v in results_bm.items():\n",
    "    for ck, cv in v.items():\n",
    "        if len(cv) > 1:\n",
    "            print(k, v)\n",
    "            n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10782, 1400, 10782, 1, 979)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serank = []\n",
    "better_serank = 0\n",
    "for k, v in results_bm.items():\n",
    "    for ck, cv in v.items():\n",
    "        serank.append(cv[0][0])\n",
    "        if cv[0][0] > 1000: print(k, v)\n",
    "        if cv[0][0] < cv[0][1]: better_serank += 1\n",
    "len(results_bm), better_serank, len(serank), min(serank), max(serank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              \tTop1    \tTop10   \tTop20   \tTop100  \n",
      "------------------------------------------------------------------------------------------\n",
      "Test Citations in SQL/TFIDF   \t10782   \t9916    \t9916    \n",
      "SQL Search Results            \t3424    \t6189    \t6915    \t8416    \n",
      "SQL Search Results R@k        \t0.3453  \t0.6241  \t0.6974  \t0.8487  \n",
      "SQL Search Results MAP        \t0.3453  \t0.0624  \t0.0349  \t0.0085  \n",
      "SQL Search Results MRR        \t0.3453  \t0.4320  \t0.4371  \t0.4409  \n",
      "\n",
      "SQL Rerank Results            \t3995    \t7227    \t8033    \t9323    \n",
      "SQL Rerank Results R@k        \t0.4029  \t0.7288  \t0.8101  \t0.9402  \n",
      "SQL Rerank Results MAP        \t0.4029  \t0.0729  \t0.0405  \t0.0094  \n",
      "SQL Rerank Results MRR        \t0.4029  \t0.5047  \t0.5104  \t0.5137  \n",
      "\n",
      "TFIDF Search Results          \t2120    \t4598    \t5398    \t7305    \n",
      "TFIDF Search Results R@k      \t0.2138  \t0.4637  \t0.5444  \t0.7367  \n",
      "TFIDF Search Results MAP      \t0.2138  \t0.0464  \t0.0272  \t0.0074  \n",
      "TFIDF Search Results MRR      \t0.2138  \t0.2883  \t0.2940  \t0.2986  \n",
      "\n",
      "TFIDF Rerank Results          \t3512    \t6714    \t7574    \t9083    \n",
      "TFIDF Rerank Results R@k      \t0.3542  \t0.6771  \t0.7638  \t0.9160  \n",
      "TFIDF Rerank Results MAP      \t0.3542  \t0.0677  \t0.0382  \t0.0092  \n",
      "TFIDF Rerank Results MRR      \t0.3542  \t0.4525  \t0.4585  \t0.4625  \n",
      "\n",
      "BM Search Results             \t424     \t2854    \t3909    \t6229    \n",
      "BM Search Results R@k         \t0.0428  \t0.2878  \t0.3942  \t0.6282  \n",
      "BM Search Results MAP         \t0.0428  \t0.0288  \t0.0197  \t0.0063  \n",
      "BM Search Results MRR         \t0.0428  \t0.1032  \t0.1106  \t0.1164  \n",
      "\n",
      "BM Rerank Results             \t4201    \t7210    \t7952    \t9270    \n",
      "BM Rerank Results R@k         \t0.4237  \t0.7271  \t0.8019  \t0.9349  \n",
      "BM Rerank Results MAP         \t0.4237  \t0.0727  \t0.0401  \t0.0093  \n",
      "BM Rerank Results MRR         \t0.4237  \t0.5191  \t0.5243  \t0.5278  \n"
     ]
    }
   ],
   "source": [
    "n_sql, n_tfidf = 0, 0\n",
    "n_sql_se_1, n_sql_se_10, n_sql_se_20, n_sql_se_100 = 0, 0, 0, 0\n",
    "rr_sql_se_10, rr_sql_se_20, rr_sql_se_100 = [], [], []\n",
    "n_sql_re_1, n_sql_re_10, n_sql_re_20, n_sql_re_100 = 0, 0, 0, 0\n",
    "rr_sql_re_10, rr_sql_re_20, rr_sql_re_100 = [], [], []\n",
    "\n",
    "n_tfidf_se_1, n_tfidf_se_10, n_tfidf_se_20, n_tfidf_se_100 = 0, 0, 0, 0\n",
    "rr_tfidf_se_10, rr_tfidf_se_20, rr_tfidf_se_100 = [], [], []\n",
    "n_tfidf_re_1, n_tfidf_re_10, n_tfidf_re_20, n_tfidf_re_100 = 0, 0, 0, 0\n",
    "rr_tfidf_re_10, rr_tfidf_re_20, rr_tfidf_re_100 = [], [], []\n",
    "\n",
    "n_bm_se_1, n_bm_se_10, n_bm_se_20, n_bm_se_100 = 0, 0, 0, 0\n",
    "rr_bm_se_10, rr_bm_se_20, rr_bm_se_100 = [], [], []\n",
    "n_bm_re_1, n_bm_re_10, n_bm_re_20, n_bm_re_100 = 0, 0, 0, 0\n",
    "rr_bm_re_10, rr_bm_re_20, rr_bm_re_100 = [], [], []\n",
    "\n",
    "for k,v in results_bm.items():\n",
    "    if k in results_sql and k in results_tfidf:\n",
    "        n_sql += 1\n",
    "        for i in v:\n",
    "            if i in results_sql[k] and i in results_tfidf[k]:\n",
    "                n_tfidf += 1\n",
    "                if results_sql[k][i][0][0] == 1: n_sql_se_1 += 1\n",
    "                if results_sql[k][i][0][0] <= 10:\n",
    "                    n_sql_se_10 += 1\n",
    "                    rr_sql_se_10.append(1/results_sql[k][i][0][0])\n",
    "                if results_sql[k][i][0][0] <= 20:\n",
    "                    n_sql_se_20 += 1\n",
    "                    rr_sql_se_20.append(1/results_sql[k][i][0][0])\n",
    "                if results_sql[k][i][0][0] <= 100:\n",
    "                    n_sql_se_100 += 1\n",
    "                    rr_sql_se_100.append(1/results_sql[k][i][0][0])\n",
    "                \n",
    "                if results_sql[k][i][0][1] == 1: n_sql_re_1 += 1\n",
    "                if results_sql[k][i][0][1] <= 10:\n",
    "                    n_sql_re_10 += 1\n",
    "                    rr_sql_re_10.append(1/results_sql[k][i][0][1])\n",
    "                if results_sql[k][i][0][1] <= 20:\n",
    "                    n_sql_re_20 += 1\n",
    "                    rr_sql_re_20.append(1/results_sql[k][i][0][1])\n",
    "                if results_sql[k][i][0][1] <= 100:\n",
    "                    n_sql_re_100 += 1\n",
    "                    rr_sql_re_100.append(1/results_sql[k][i][0][1])\n",
    "                \n",
    "                if results_tfidf[k][i][0][0] == 1: n_tfidf_se_1 += 1\n",
    "                if results_tfidf[k][i][0][0] <= 10:\n",
    "                    n_tfidf_se_10 += 1\n",
    "                    rr_tfidf_se_10.append(1/results_tfidf[k][i][0][0])\n",
    "                if results_tfidf[k][i][0][0] <= 20:\n",
    "                    n_tfidf_se_20 += 1\n",
    "                    rr_tfidf_se_20.append(1/results_tfidf[k][i][0][0])\n",
    "                if results_tfidf[k][i][0][0] <= 100:\n",
    "                    n_tfidf_se_100 += 1\n",
    "                    rr_tfidf_se_100.append(1/results_tfidf[k][i][0][0])\n",
    "                \n",
    "                if results_tfidf[k][i][0][1] == 1: n_tfidf_re_1 += 1\n",
    "                if results_tfidf[k][i][0][1] <= 10:\n",
    "                    n_tfidf_re_10 += 1\n",
    "                    rr_tfidf_re_10.append(1/results_tfidf[k][i][0][1])\n",
    "                if results_tfidf[k][i][0][1] <= 20:\n",
    "                    n_tfidf_re_20 += 1\n",
    "                    rr_tfidf_re_20.append(1/results_tfidf[k][i][0][1])\n",
    "                if results_tfidf[k][i][0][1] <= 100:\n",
    "                    n_tfidf_re_100 += 1\n",
    "                    rr_tfidf_re_100.append(1/results_tfidf[k][i][0][1])\n",
    "                \n",
    "                if results_bm[k][i][0][0] == 1: n_bm_se_1 += 1\n",
    "                if results_bm[k][i][0][0] <= 10:\n",
    "                    n_bm_se_10 += 1\n",
    "                    rr_bm_se_10.append(1/results_bm[k][i][0][0])\n",
    "                if results_bm[k][i][0][0] <= 20:\n",
    "                    n_bm_se_20 += 1\n",
    "                    rr_bm_se_20.append(1/results_bm[k][i][0][0])\n",
    "                if results_bm[k][i][0][0] <= 100:\n",
    "                    n_bm_se_100 += 1\n",
    "                    rr_bm_se_100.append(1/results_bm[k][i][0][0])\n",
    "                \n",
    "                if results_bm[k][i][0][1] == 1: n_bm_re_1 += 1\n",
    "                if results_bm[k][i][0][1] <= 10:\n",
    "                    n_bm_re_10 += 1\n",
    "                    rr_bm_re_10.append(1/results_bm[k][i][0][1])\n",
    "                if results_bm[k][i][0][1] <= 20:\n",
    "                    n_bm_re_20 += 1\n",
    "                    rr_bm_re_20.append(1/results_bm[k][i][0][1])\n",
    "                if results_bm[k][i][0][1] <= 100:\n",
    "                    n_bm_re_100 += 1\n",
    "                    rr_bm_re_100.append(1/results_bm[k][i][0][1])\n",
    "                    \n",
    "print(f\"{' ':30}\\t{'Top1':8}\\t{'Top10':8}\\t{'Top20':8}\\t{'Top100':8}\")\n",
    "print(f\"{90*'-'}\")\n",
    "print(f\"{'Test Citations in SQL/TFIDF':30}\\t{len(results_bm):<8}\\t{n_sql:<8}\\t{n_tfidf:<8}\")\n",
    "print(f\"{'SQL Search Results':30}\\t{n_sql_se_1:<8}\\t{n_sql_se_10:<8}\\t{n_sql_se_20:<8}\\t{n_sql_se_100:<8}\")\n",
    "print(f\"{'SQL Search Results R@k':30}\\t{n_sql_se_1/n_tfidf:<8.4f}\\t{n_sql_se_10/n_tfidf:<8.4f}\\t{n_sql_se_20/n_tfidf:<8.4f}\\t{n_sql_se_100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'SQL Search Results MAP':30}\\t{n_sql_se_1/n_tfidf:<8.4f}\\t{n_sql_se_10*1/10/n_tfidf:<8.4f}\\t{n_sql_se_20*1/20/n_tfidf:<8.4f}\\t{n_sql_se_100*1/100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'SQL Search Results MRR':30}\\t{n_sql_se_1/n_tfidf:<8.4f}\\t{sum(rr_sql_se_10)/n_tfidf:<8.4f}\\t{sum(rr_sql_se_20)/n_tfidf:<8.4f}\\t{sum(rr_sql_se_100)/n_tfidf:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'SQL Rerank Results':30}\\t{n_sql_re_1:<8}\\t{n_sql_re_10:<8}\\t{n_sql_re_20:<8}\\t{n_sql_re_100:<8}\")\n",
    "print(f\"{'SQL Rerank Results R@k':30}\\t{n_sql_re_1/n_tfidf:<8.4f}\\t{n_sql_re_10/n_tfidf:<8.4f}\\t{n_sql_re_20/n_tfidf:<8.4f}\\t{n_sql_re_100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'SQL Rerank Results MAP':30}\\t{n_sql_re_1/n_tfidf:<8.4f}\\t{n_sql_re_10*1/10/n_tfidf:<8.4f}\\t{n_sql_re_20*1/20/n_tfidf:<8.4f}\\t{n_sql_re_100*1/100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'SQL Rerank Results MRR':30}\\t{n_sql_re_1/n_tfidf:<8.4f}\\t{sum(rr_sql_re_10)/n_tfidf:<8.4f}\\t{sum(rr_sql_re_20)/n_tfidf:<8.4f}\\t{sum(rr_sql_re_100)/n_tfidf:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Search Results':30}\\t{n_tfidf_se_1:<8}\\t{n_tfidf_se_10:<8}\\t{n_tfidf_se_20:<8}\\t{n_tfidf_se_100:<8}\")\n",
    "print(f\"{'TFIDF Search Results R@k':30}\\t{n_tfidf_se_1/n_tfidf:<8.4f}\\t{n_tfidf_se_10/n_tfidf:<8.4f}\\t{n_tfidf_se_20/n_tfidf:<8.4f}\\t{n_tfidf_se_100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'TFIDF Search Results MAP':30}\\t{n_tfidf_se_1/n_tfidf:<8.4f}\\t{n_tfidf_se_10*1/10/n_tfidf:<8.4f}\\t{n_tfidf_se_20*1/20/n_tfidf:<8.4f}\\t{n_tfidf_se_100*1/100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'TFIDF Search Results MRR':30}\\t{n_tfidf_se_1/n_tfidf:<8.4f}\\t{sum(rr_tfidf_se_10)/n_tfidf:<8.4f}\\t{sum(rr_tfidf_se_20)/n_tfidf:<8.4f}\\t{sum(rr_tfidf_se_100)/n_tfidf:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'TFIDF Rerank Results':30}\\t{n_tfidf_re_1:<8}\\t{n_tfidf_re_10:<8}\\t{n_tfidf_re_20:<8}\\t{n_tfidf_re_100:<8}\")\n",
    "print(f\"{'TFIDF Rerank Results R@k':30}\\t{n_tfidf_re_1/n_tfidf:<8.4f}\\t{n_tfidf_re_10/n_tfidf:<8.4f}\\t{n_tfidf_re_20/n_tfidf:<8.4f}\\t{n_tfidf_re_100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'TFIDF Rerank Results MAP':30}\\t{n_tfidf_re_1/n_tfidf:<8.4f}\\t{n_tfidf_re_10*1/10/n_tfidf:<8.4f}\\t{n_tfidf_re_20*1/20/n_tfidf:<8.4f}\\t{n_tfidf_re_100*1/100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'TFIDF Rerank Results MRR':30}\\t{n_tfidf_re_1/n_tfidf:<8.4f}\\t{sum(rr_tfidf_re_10)/n_tfidf:<8.4f}\\t{sum(rr_tfidf_re_20)/n_tfidf:<8.4f}\\t{sum(rr_tfidf_re_100)/n_tfidf:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'BM Search Results':30}\\t{n_bm_se_1:<8}\\t{n_bm_se_10:<8}\\t{n_bm_se_20:<8}\\t{n_bm_se_100:<8}\")\n",
    "print(f\"{'BM Search Results R@k':30}\\t{n_bm_se_1/n_tfidf:<8.4f}\\t{n_bm_se_10/n_tfidf:<8.4f}\\t{n_bm_se_20/n_tfidf:<8.4f}\\t{n_bm_se_100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'BM Search Results MAP':30}\\t{n_bm_se_1/n_tfidf:<8.4f}\\t{n_bm_se_10*1/10/n_tfidf:<8.4f}\\t{n_bm_se_20*1/20/n_tfidf:<8.4f}\\t{n_bm_se_100*1/100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'BM Search Results MRR':30}\\t{n_bm_se_1/n_tfidf:<8.4f}\\t{sum(rr_bm_se_10)/n_tfidf:<8.4f}\\t{sum(rr_bm_se_20)/n_tfidf:<8.4f}\\t{sum(rr_bm_se_100)/n_tfidf:<8.4f}\")\n",
    "print()\n",
    "print(f\"{'BM Rerank Results':30}\\t{n_bm_re_1:<8}\\t{n_bm_re_10:<8}\\t{n_bm_re_20:<8}\\t{n_bm_re_100:<8}\")\n",
    "print(f\"{'BM Rerank Results R@k':30}\\t{n_bm_re_1/n_tfidf:<8.4f}\\t{n_bm_re_10/n_tfidf:<8.4f}\\t{n_bm_re_20/n_tfidf:<8.4f}\\t{n_bm_re_100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'BM Rerank Results MAP':30}\\t{n_bm_re_1/n_tfidf:<8.4f}\\t{n_bm_re_10*1/10/n_tfidf:<8.4f}\\t{n_bm_re_20*1/20/n_tfidf:<8.4f}\\t{n_bm_re_100*1/100/n_tfidf:<8.4f}\")\n",
    "print(f\"{'BM Rerank Results MRR':30}\\t{n_bm_re_1/n_tfidf:<8.4f}\\t{sum(rr_bm_re_10)/n_tfidf:<8.4f}\\t{sum(rr_bm_re_20)/n_tfidf:<8.4f}\\t{sum(rr_bm_re_100)/n_tfidf:<8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
